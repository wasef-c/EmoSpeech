{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d312506-4b7b-4a69-9850-5f56fd25f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/wasef-c/EmoSpeech.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc211f98-57f9-44ec-9022-a96c4b43e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers[torch] datasets scikit-learn matplotlib seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc02d993-0ad8-41e2-954a-80c57c527e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pillow\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f30c096-745c-4386-bd90-e97ca6a55bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install natten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600e7519-9e32-4df3-af64-06b0c1799a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "134c0009-6b3d-4290-8c84-5e3c9c5ec6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install natten==0.17.3+torch210cu118 -f https://shi-labs.com/natten/wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ba7905-f64e-4f3b-ae2f-2d74deb1974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece\n",
    "# !pip install googletrans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517657bf-f3f7-4b02-bcd2-419ff5ee0a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in dataset: {'S', 'U', 'X', 'N', 'A', 'O', 'C', 'D', 'F', 'H'}\n",
      "Unique labels in train_dataset: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "OrderedDict([(0, (0, 2520)), (1, (2520, 25960)), (2, (25960, 40715)), (3, (40715, 46283)), (4, (46283, 48836)), (5, (48836, 49767)), (6, (49767, 57764)), (7, (57764, 58993))])\n",
      "Class distribution before balancing:\n",
      "Label 0: 2520 samples\n",
      "Label 1: 23440 samples\n",
      "Label 2: 14755 samples\n",
      "Label 3: 5568 samples\n",
      "Label 4: 2553 samples\n",
      "Label 5: 931 samples\n",
      "Label 6: 7997 samples\n",
      "Label 7: 1229 samples\n",
      "Per-label target size: 7374\n",
      "OrderedDict([(0, (0, 630)), (1, (630, 6523)), (2, (6523, 10176)), (3, (10176, 11532)), (4, (11532, 12130)), (5, (12130, 12369)), (6, (12369, 14412)), (7, (14412, 14749))])\n",
      "Class distribution before balancing:\n",
      "Per-label target size: 1843\n",
      "Test dataset size: 18436\n",
      "Train dataset size: 58993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DinatForImageClassification were not initialized from the model checkpoint at shi-labs/dinat-mini-in1k-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([8, 512]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([8]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/50:   0%|          | 0/984 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training Loss: 4.4787\n",
      "Validation Loss: nan, Accuracy: 0.3030, UAR: 0.3030, F1: 0.2596, UAR STD: 0.2216626007006973 \n",
      "Per-class Recall: [0.04449267 0.24091156 0.31144872 0.67335865 0.31036354 0.00434075\n",
      " 0.60499186 0.23440043]\n",
      " Comparison metric: 0.2274220721808813\n",
      "Confusion matrix saved to: ./DinatMEL/20250130_6/Epoch0_val_confusion_matrix.png\n",
      "Validation uar improved. Best model saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/50:   0%|          | 0/984 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 - Training Loss: 4.1963\n",
      "Validation Loss: nan, Accuracy: 0.3286, UAR: 0.3286, F1: 0.2899, UAR STD: 0.21628275898072583 \n",
      "Per-class Recall: [0.07487792 0.2794357  0.41888226 0.6863809  0.29408573 0.0168204\n",
      " 0.59142702 0.26695605]\n",
      " Comparison metric: 0.2481140579346619\n",
      "Confusion matrix saved to: ./DinatMEL/20250130_6/Epoch1_val_confusion_matrix.png\n",
      "Validation uar improved. Best model saved.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352eb8f71b7848688ef48b6035ff648b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/50:   0%|          | 0/984 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 381\u001b[0m\n\u001b[1;32m    378\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    379\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 381\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[1;32m    382\u001b[0m     pixel_values \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    383\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py:2786\u001b[0m, in \u001b[0;36mDataset.__getitems__\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m   2784\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(keys)\n\u001b[1;32m   2785\u001b[0m n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[0;32m-> 2786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py:2786\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2784\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(keys)\n\u001b[1;32m   2785\u001b[0m n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[0;32m-> 2786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py:2786\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2784\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(keys)\n\u001b[1;32m   2785\u001b[0m n_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[0;32m-> 2786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "#BEST SO FAR: 20250128_14\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import random\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    DinatForImageClassification,\n",
    "    TrainingArguments,\n",
    "    get_scheduler,\n",
    "    BertModel,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "# Hugging Face Datasets\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "# Data processing and metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.auto import tqdm\n",
    "best_epoch = 0\n",
    "# Custom functions (from your own module)\n",
    "from functionsV3 import *\n",
    "import numpy as np\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "label_mapping = {\n",
    "    0: 'C',\n",
    "    1: 'N',\n",
    "    2: 'H',\n",
    "    3: 'S',\n",
    "    4: 'U',\n",
    "    5: 'F',\n",
    "    6: 'A',\n",
    "    7: 'D'\n",
    "}\n",
    "#{0: 'C', 1: 'N', 2: 'H', 3: 'S', 4: 'U', 5: 'F', 6: 'A', 7: 'D'}\n",
    "# Directories and Model Config\n",
    "base_dir = r\"./DinatMEL\"\n",
    "output_dir = create_unique_output_dir(base_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "DATASET_PATH = \"../data\"\n",
    "# CHECKPOINT_PATH = \"./NLPIMG_Model_001\"\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = \"shi-labs/dinat-mini-in1k-224\"  # For processor loading if needed\n",
    "checkpoint_path = \"./EmoDom/best_model.pt\"\n",
    "# checkpoint_path = \"./DinatMEL/20250126_3/best_model.pt\"\n",
    "# checkpoint_path = \"./DinatMEL/20250125_1/best_model.pt\"\n",
    "pretrain_model = model_path\n",
    "bert_model_name = \"bert-base-uncased\"\n",
    "BATCH_SIZE = 60\n",
    "\n",
    "# Load Dataset\n",
    "dataset_name = \"cairocode/MSPP_MEL_6\"\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "unique_labels = set(dataset['train']['EmoClass'])\n",
    "print(\"Unique labels in dataset:\", unique_labels)\n",
    "\n",
    "\n",
    "# Reverse the mapping for efficient lookup\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Define a filtering function\n",
    "def is_mappable(example):\n",
    "    return example[\"EmoClass\"] in reverse_label_mapping\n",
    "\n",
    "column  = \"label\"\n",
    "\n",
    "# Filter out rows with unmappable values\n",
    "filtered_dataset = dataset.filter(is_mappable)\n",
    "\n",
    "# Map the filtered dataset to add the new column\n",
    "filtered_dataset = filtered_dataset.map(lambda x: {\"label\": reverse_label_mapping[x[\"EmoClass\"]]})\n",
    "\n",
    "\n",
    "# Define a filtering function\n",
    "def is_valid_transcript(example):\n",
    "    return isinstance(example['transcript'], str)\n",
    "\n",
    "\n",
    "# Filter out non-string transcripts in each split\n",
    "filtered_dataset = filtered_dataset.filter(is_valid_transcript)\n",
    "\n",
    "inv_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Step 2: Specify an order for the numeric labels\n",
    "ordered_labels_numeric = [0, 1, 2, 3, 4, 5, 6, 7 ]#, 7]\n",
    "ordered_labels_str = [label_mapping[i] for i in ordered_labels_numeric]\n",
    "\n",
    "# all_test_labels = [...]\n",
    "# all_test_predictions = [...]\n",
    "\n",
    "# Step 3: Generate the confusion matrix\n",
    "\n",
    "train_test_split = filtered_dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "train_val_split = train_test_split['train'].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "train_dataset = train_val_split['train']\n",
    "# Assuming the labels are stored in the 'label' column\n",
    "unique_labels = set(train_dataset['label'])\n",
    "print(\"Unique labels in train_dataset:\", unique_labels)\n",
    "# Sort the train dataset by the 'label' column\n",
    "\n",
    "\n",
    "sorted_train = train_dataset.sort(\"label\")\n",
    "label_boundaries = get_label_boundaries(sorted_train, \"label\")\n",
    "print(label_boundaries)\n",
    "# Print the class distribution before balancing using label boundaries\n",
    "# Initialize the count array with zeros\n",
    "count = np.zeros((8,), dtype=int)\n",
    "\n",
    "print(\"Class distribution before balancing:\")\n",
    "\n",
    "# Assuming label_boundaries is a dictionary like {0: (0, 50), 1: (51, 100), ...}\n",
    "for lbl, (start, end) in label_boundaries.items():\n",
    "    count[lbl] = end - start\n",
    "    print(f\"Label {lbl}: {count[lbl]} samples\")\n",
    "\n",
    "# Calculate the average target size per class\n",
    "avg_count = int(np.mean(count))\n",
    "print(\"Per-label target size:\", avg_count)\n",
    "\n",
    "\n",
    "# Balance the dataset\n",
    "balanced_train_dataset = balance_dataset_by_sort(\n",
    "    sorted_train,\n",
    "    label_boundaries,\n",
    "    avg_count,\n",
    "    label_column=\"label\",\n",
    "    seed=42\n",
    ")\n",
    "# balanced_train_dataset = train_dataset\n",
    "\n",
    "# # Compute new label boundaries for the balanced dataset\n",
    "# balanced_label_boundaries = get_label_boundaries(\n",
    "#     balanced_train_dataset.sort(\"label\"),\n",
    "#     \"label\"\n",
    "# )\n",
    "\n",
    "# # Print the class distribution after balancing\n",
    "# print(\"\\nClass distribution after balancing:\")\n",
    "# for lbl, (start, end) in balanced_label_boundaries.items():\n",
    "#     count = end - start\n",
    "#     print(f\"Label {lbl}: {count} samples\")\n",
    "\n",
    "# # Final size of the balanced dataset\n",
    "# print(\"\\nFinal balanced training size:\", len(balanced_train_dataset))\n",
    "\n",
    "\n",
    "\n",
    "val_dataset = train_val_split['test']\n",
    "sorted_val = val_dataset.sort(\"label\")\n",
    "label_boundaries = get_label_boundaries(sorted_val, \"label\")\n",
    "print(label_boundaries)\n",
    "# Print the class distribution before balancing using label boundaries\n",
    "# Initialize the count array with zeros\n",
    "count = np.zeros((8,), dtype=int)\n",
    "\n",
    "print(\"Class distribution before balancing:\")\n",
    "\n",
    "# Assuming label_boundaries is a dictionary like {0: (0, 50), 1: (51, 100), ...}\n",
    "for lbl, (start, end) in label_boundaries.items():\n",
    "    count[lbl] = end - start\n",
    "    # print(f\"Label {lbl}: {count[lbl]} samples\")\n",
    "\n",
    "# Calculate the average target size per class\n",
    "avg_count = int(np.mean(count))\n",
    "print(\"Per-label target size:\", avg_count)\n",
    "\n",
    "\n",
    "# Balance the dataset\n",
    "balanced_val_dataset = balance_dataset_by_sort(\n",
    "    sorted_val,\n",
    "    label_boundaries,\n",
    "    avg_count,\n",
    "    label_column=\"label\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_dataset = balanced_val_dataset\n",
    "\n",
    "test_dataset = train_test_split['test']\n",
    "num_labels = 8\n",
    "print(\"Test dataset size:\", len(test_dataset))\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "\n",
    "class_weights = calculate_class_weights(\n",
    "    train_dataset)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "# class_weoghts = torch(ones)\n",
    "# Transforms (assumed imported from functions_old)\n",
    "balanced_train_dataset.set_transform(train_transforms)\n",
    "train_dataset.set_transform(train_transforms)\n",
    "val_dataset.set_transform(val_transforms)\n",
    "test_dataset.set_transform(val_transforms)\n",
    "\n",
    "train_sampler = CustomSampler(train_dataset)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    balanced_train_dataset,\n",
    "    # sampler=train_sampler,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda examples: collate_fn_reg(examples, column=column),\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=lambda examples: collate_fn_reg(examples, column=column),\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=lambda examples: collate_fn_reg(examples, column=column),\n",
    ")\n",
    "\n",
    "\n",
    "# Load Models\n",
    "image_model = DinatForImageClassification.from_pretrained(\n",
    "    pretrain_model,\n",
    "    num_labels=num_labels,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    problem_type=\"single_label_classification\",\n",
    ").to(device)\n",
    "\n",
    "processor = DinatForImageClassification.from_pretrained(model_path).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name).to(device)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Initialize the Combined Regression Model\n",
    "# ----------------------------------------------------------------------\n",
    "unfozen_layers = [10,11]\n",
    "next_layer_to_unfreeze = unfozen_layers[0]-1\n",
    " \n",
    "model = CombinedModelsBi(\n",
    "    image_model=image_model,\n",
    "    bert_model=bert_model,\n",
    "    image_feature_dim=512,\n",
    "    bert_embedding_dim=768,\n",
    "    combined_dim=512,\n",
    "    num_labels=num_labels,\n",
    "    unfrozen_layers = unfozen_layers\n",
    "\n",
    ").to(device)\n",
    "\n",
    "if checkpoint_path != None:\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    # # Define the keywords to include and exclude\n",
    "    include_keyword = \"model\"\n",
    "    exclude_keys = {\n",
    "        \"image_model.classifier.weight\",\n",
    "        \"image_model.classifier.bias\",\n",
    "        \"fc3\"\n",
    "    }\n",
    "\n",
    "    # Use dictionary comprehension to filter the keys\n",
    "    filtered_checkpoint = {\n",
    "        key: value for key, value in checkpoint.items()\n",
    "        if include_keyword in key and key not in exclude_keys\n",
    "    }\n",
    "    # Load the filtered state dict\n",
    "    # filtered_checkpoint = checkpoint\n",
    "    model.load_state_dict(filtered_checkpoint, strict=False)\n",
    "\n",
    "\n",
    "# model.load_state_dict(torch.load(\"/media/carol/Data/Documents/Emo_rec/Notebooks/DINAT_BERT/MSPP_COMP/20250105_11/best_model.pt\"))\n",
    "#Mapping of categories to integers: {'D': 0, 'H': 1, 'A': 2, 'O': 3, 'N': 4, 'C': 5, 'F': 6, 'S': 7}\n",
    "#Mapping of categories to integers: {'F': 0, 'O': 1, 'H': 2, 'D': 3, 'A': 4, 'S': 5, 'N': 6, 'C': 7}\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./logs\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "logging.getLogger().addHandler(logging.NullHandler())\n",
    "logging.getLogger(\"natten.functional\").setLevel(logging.ERROR)\n",
    "\n",
    "# Optimizer & Scheduler\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=training_args.learning_rate,\n",
    "    weight_decay=training_args.weight_decay\n",
    ")\n",
    "\n",
    "num_training_steps = len(train_loader) * training_args.num_train_epochs\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=training_args.warmup_steps,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "focal_loss = AdaptiveLearnableFocalLoss(class_weights=class_weights)\n",
    "focal_loss = AdaptiveLearnableFocalLoss()\n",
    "\n",
    "focal_loss = AdaptiveLearnableFocalLoss_V2(num_classes = num_labels)\n",
    "# cecc_loss= CrossEntropyWithContrastiveCenterLoss(\n",
    "#     num_classes=8,  # Number of emotion classes\n",
    "#     feature_dim=512,  # Feature dimension from fc2\n",
    "#     alpha=1,  # Adjust weights for CE vs Contrastive-Center\n",
    "#     beta=0.2\n",
    "# )\n",
    "#1.0, beta=0.01\n",
    "cecc_loss= BalancedCrossEntropyWithContrastiveLoss(\n",
    "    num_classes=8,  # Number of emotion classes\n",
    "    feature_dim=512,  # Feature dimension from fc2\n",
    "    alpha=1.5,  # Adjust weights for CE vs Contrastive-Center\n",
    "    beta=0.02,\n",
    "    gamma = 1\n",
    ")\n",
    "\n",
    "\n",
    "# BalancedCrossEntropyWithContrastiveLoss 0.01\n",
    "\n",
    "'''\n",
    "Start with alpha=0.5, beta=1.0, gamma=0.5\n",
    "If UAR is too low, increase alpha\n",
    "If STD is too high, increase gamma\n",
    "If classes are not well-separated, increase beta\n",
    "\n",
    "alpha=0.5, beta=1.0, gamma=0.5\n",
    "'''\n",
    "\n",
    "# Training Variables\n",
    "num_epochs = training_args.num_train_epochs\n",
    "patience = 12\n",
    "best_val_accuracy = 0\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses, val_losses, epochs_list = [], [], []\n",
    "\n",
    "best_model_path = os.path.join(output_dir, \"best_model.pt\")\n",
    "class_weights = None\n",
    "##############################################################################\n",
    "# Training Loop\n",
    "##############################################################################\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            pixel_values=pixel_values,\n",
    "            bert_input_ids=input_ids,\n",
    "            bert_attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs[\"logits\"]\n",
    "        features =  outputs[\"combined_features\"]\n",
    "\n",
    "        loss = cecc_loss(logits,features, labels)\n",
    "        # loss = focal_loss(logits, labels)\n",
    "\n",
    "        # focal_loss = AdaptiveLearnableFocalLoss_V2(num_classes = num_labels, class_weights = class_weights)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"Loss\": loss.item()})\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {avg_train_loss:.4f}\")\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_predictions, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                pixel_values=pixel_values,\n",
    "                bert_input_ids=input_ids,\n",
    "                bert_attention_mask=attention_mask\n",
    "            )\n",
    "            logits = outputs[\"logits\"]\n",
    "            features =  outputs[\"combined_features\"]\n",
    "\n",
    "            loss = cecc_loss(logits,features, labels)\n",
    "\n",
    "            # loss = focal_loss(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    uar = recall_score(all_labels, all_predictions, average=\"macro\")\n",
    "    f1 = f1_score(all_labels, all_predictions, average=\"macro\")\n",
    "    per_class_recall = recall_score(all_labels, all_predictions, average=None)\n",
    "    uar_std = np.std(per_class_recall)\n",
    "\n",
    "    gamma = 1.5\n",
    "    comparison_metric = uar / (1 + gamma * uar_std)\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    epochs_list.append(epoch + 1)\n",
    "\n",
    "    print(\n",
    "        f\"Validation Loss: {avg_val_loss:.4f}, \"\n",
    "        f\"Accuracy: {accuracy:.4f}, UAR: {uar:.4f}, F1: {f1:.4f}, UAR STD: {uar_std} \"\n",
    "        f\"\\nPer-class Recall: {per_class_recall}\"\n",
    "        f\"\\n Comparison metric: {comparison_metric}\"\n",
    "\n",
    "    )\n",
    "    plot_and_save_confusion_matrix(all_labels, all_predictions, ordered_labels_str, output_dir, epoch=epoch)\n",
    "\n",
    "\n",
    "    # Early Stopping based on Accuracy\n",
    "    if comparison_metric > best_val_accuracy:\n",
    "        best_val_accuracy = comparison_metric\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        torch.save(model.image_model.state_dict(), \"fine_tuned_image_model.pth\")\n",
    "        best_epoch = epoch\n",
    "        print(\"Validation uar improved. Best model saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    # epoch_dir = os.path.join(output_dir, f\"Epoch_{epoch}_model.pt\")\n",
    "    # torch.save(model.state_dict(), epoch_dir)\n",
    "\n",
    "    # import torch\n",
    "    \n",
    "    # epsilon = 0.1\n",
    "    # class_weights = [(1 - r) + epsilon for r in per_class_recall]\n",
    "    # class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    \n",
    "    # print(\"Computed class_weights:\", class_weights)\n",
    "\n",
    "    if (epoch + 1) % 3 == 0 and next_layer_to_unfreeze >= 0:\n",
    "            print(f\"Unfreezing BERT layer {next_layer_to_unfreeze}\")\n",
    "            unfreeze_bert_layer(model.bert_model, next_layer_to_unfreeze)\n",
    "            \n",
    "            next_layer_to_unfreeze -= 1\n",
    "\n",
    "\n",
    "# Load Best Model\n",
    "print(\"Loading best model for final evaluation.\")\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "\n",
    "##############################################################################\n",
    "# Test Evaluation\n",
    "##############################################################################\n",
    "print(\"\\nStarting Test Evaluation...\")\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "all_test_predictions, all_test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "    for batch in test_progress_bar:\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            pixel_values=pixel_values,\n",
    "            bert_input_ids=input_ids,\n",
    "            bert_attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs[\"logits\"]\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        all_test_predictions.extend(predictions.cpu().numpy())\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = accuracy_score(all_test_labels, all_test_predictions)\n",
    "test_uar = recall_score(all_test_labels, all_test_predictions, average=\"macro\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_predictions, average=\"macro\")\n",
    "\n",
    "metrics_str = (\n",
    "    f\"Test Loss: {avg_test_loss:.4f}, \"\n",
    "    f\"Accuracy: {test_accuracy:.4f}, \"\n",
    "    f\"UAR: {test_uar:.4f}, \"\n",
    "    f\"F1: {test_f1:.4f}\"\n",
    ")\n",
    "print(metrics_str)\n",
    "\n",
    "\n",
    "# Step 1: Define your label mapping\n",
    "# label_mapping = {'D': 0, 'H': 1, 'A': 2, 'O': 3, 'N': 4, 'C': 5, 'F': 6, 'S': 7}\n",
    "inv_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Step 2: Specify an order for the numeric labels\n",
    "ordered_labels_numeric = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "ordered_labels_str = [label_mapping[i] for i in ordered_labels_numeric]\n",
    "\n",
    "# Suppose these are your test labels and predictions (as numeric):\n",
    "# all_test_labels = [...]\n",
    "# all_test_predictions = [...]\n",
    "\n",
    "\n",
    "# Step 2: Specify an order for the numeric labels\n",
    "ordered_labels_numeric = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "ordered_labels_str = [label_mapping[i] for i in ordered_labels_numeric]\n",
    "\n",
    "# Suppose these are your test labels and predictions (as numeric):\n",
    "# all_test_labels = [...]\n",
    "# all_test_predictions = [...]\n",
    "\n",
    "# # Step 3: Generate the confusion matrix\n",
    "# cm = confusion_matrix(\n",
    "#     y_true=all_test_labels, \n",
    "#     y_pred=all_test_predictions, \n",
    "#     # labels=ordered_labels_numeric\n",
    "# )\n",
    "plot_and_save_confusion_matrix(all_test_labels, all_test_predictions, ordered_labels_str, output_dir, epoch=None)\n",
    "# # Step 4: Plot the confusion matrix with custom axis labels\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(\n",
    "#     cm,\n",
    "#     annot=True,\n",
    "#     fmt=\"d\",\n",
    "#     cmap=\"Blues\",\n",
    "#     xticklabels=ordered_labels_str,\n",
    "#     yticklabels=ordered_labels_str\n",
    "# )\n",
    "# plt.xlabel(\"Predicted Labels\")\n",
    "# plt.ylabel(\"True Labels\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# # Save and close\n",
    "# save_path = os.path.join(output_dir, \"confusion_matrix.png\")\n",
    "# plt.savefig(save_path, bbox_inches=\"tight\", dpi=300)\n",
    "# plt.close()\n",
    "# print(f\"Confusion matrix saved to: {save_path}\")\n",
    "\n",
    "# # Save Metadata\n",
    "# save_training_metadata(\n",
    "#     output_dir=output_dir,\n",
    "#     pathstr=pretrain_model,\n",
    "#     dataset_name=dataset_name,\n",
    "#     model_type=\"CombinedModelsDDCA\",\n",
    "#     super_loss_params=\"N/A\",\n",
    "#     speaker_disentanglement=True,\n",
    "#     entropy=False,\n",
    "#     column=\"label\",\n",
    "#     metrics=metrics_str,\n",
    "#     weight_decay=training_args.weight_decay,\n",
    "#     results=metrics_str\n",
    "# )\n",
    "\n",
    "# Overall Metrics (if needed across multiple runs):\n",
    "# For a single run, these will just match the test metrics.\n",
    "overall_accuracy = test_accuracy\n",
    "overall_UAR = test_uar\n",
    "overall_F1 = test_f1\n",
    "full_accuracy = test_accuracy\n",
    "\n",
    "# Save final metrics\n",
    "output_file = os.path.join(output_dir, \"metrics.txt\")\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(f\"Overall F1 Score: {overall_F1:.4f}\\n\")\n",
    "    f.write(f\"Overall Accuracy: {overall_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Full Accuracy: {full_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Overall UAR: {overall_UAR:.4f}\\n\")\n",
    "    f.write(f\" Class Mapping :{label_mapping}\\n\")\n",
    "    f.write(f\" Best Epoch :{best_epoch}\\n\")\n",
    "\n",
    "print(f\"Metrics saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91f124-a36d-4e6b-943d-6cbb1cf9438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f686e-5351-4f41-8da9-bc36b45bf4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Best Model\n",
    "print(\"Loading best model for final evaluation.\")\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "\n",
    "##############################################################################\n",
    "# Test Evaluation\n",
    "##############################################################################\n",
    "print(\"\\nStarting Test Evaluation...\")\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "all_test_predictions, all_test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "    for batch in test_progress_bar:\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            pixel_values=pixel_values,\n",
    "            bert_input_ids=input_ids,\n",
    "            bert_attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs[\"logits\"]\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        all_test_predictions.extend(predictions.cpu().numpy())\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = accuracy_score(all_test_labels, all_test_predictions)\n",
    "test_uar = recall_score(all_test_labels, all_test_predictions, average=\"macro\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_predictions, average=\"macro\")\n",
    "\n",
    "metrics_str = (\n",
    "    f\"Test Loss: {avg_test_loss:.4f}, \"\n",
    "    f\"Accuracy: {test_accuracy:.4f}, \"\n",
    "    f\"UAR: {test_uar:.4f}, \"\n",
    "    f\"F1: {test_f1:.4f}\"\n",
    ")\n",
    "print(metrics_str)\n",
    "\n",
    "\n",
    "# Step 1: Define your label mapping\n",
    "# label_mapping = {'D': 0, 'H': 1, 'A': 2, 'O': 3, 'N': 4, 'C': 5, 'F': 6, 'S': 7}\n",
    "inv_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Step 2: Specify an order for the numeric labels\n",
    "ordered_labels_numeric = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "ordered_labels_str = [label_mapping[i] for i in ordered_labels_numeric]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d5506-d658-418b-97df-f709bfb93df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save_confusion_matrix(all_test_labels, all_test_predictions, ordered_labels_str, output_dir, epoch=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fceca55-907b-401a-9f6d-19b48539fcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b212289-a38e-468d-886a-3f59048050e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Define your label mapping\n",
    "# label_mapping = {'D': 0, 'H': 1, 'A': 2, 'O': 3, 'N': 4, 'C': 5, 'F': 6, 'S': 7}\n",
    "inv_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Step 2: Specify an order for the numeric labels\n",
    "ordered_labels_numeric = [0, 1, 2, 3, 4, 5, 6, 7 ]#, 7]\n",
    "ordered_labels_str = [label_mapping[i] for i in ordered_labels_numeric]\n",
    "\n",
    "# all_test_labels = [...]\n",
    "# all_test_predictions = [...]\n",
    "\n",
    "# # Step 3: Generate the confusion matrix\n",
    "# cm = confusion_matrix(\n",
    "#     y_true=all_test_labels, \n",
    "#     y_pred=all_test_predictions, \n",
    "#     # labels=ordered_labels_numeric\n",
    "# )\n",
    "\n",
    "# # Step 4: Plot the confusion matrix with custom axis labels\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(\n",
    "#     cm,\n",
    "#     annot=True,\n",
    "#     fmt=\"d\",\n",
    "#     cmap=\"Blues\",\n",
    "#     xticklabels=ordered_labels_str,\n",
    "#     yticklabels=ordered_labels_str\n",
    "# )\n",
    "# plt.xlabel(\"Predicted Labels\")\n",
    "# plt.ylabel(\"True Labels\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# # Save and close\n",
    "# save_path = os.path.join(output_dir, \"confusion_matrix.png\")\n",
    "# plt.savefig(save_path, bbox_inches=\"tight\", dpi=300)\n",
    "# plt.close()\n",
    "# print(f\"Confusion matrix saved to: {save_path}\")\n",
    "\n",
    "# # # Save Metadata\n",
    "# # save_training_metadata(\n",
    "# #     output_dir=output_dir,\n",
    "# #     pathstr=pretrain_model,\n",
    "# #     dataset_name=dataset_name,\n",
    "# #     model_type=\"CombinedModelsDDCA\",\n",
    "# #     super_loss_params=\"N/A\",\n",
    "# #     speaker_disentanglement=True,\n",
    "# #     entropy=False,\n",
    "# #     column=\"label\",\n",
    "# #     metrics=metrics_str,\n",
    "# #     weight_decay=training_args.weight_decay,\n",
    "# #     results=metrics_str\n",
    "# # )\n",
    "\n",
    "# Overall Metrics (if needed across multiple runs):\n",
    "# For a single run, these will just match the test metrics.\n",
    "overall_accuracy = test_accuracy\n",
    "overall_UAR = test_uar\n",
    "overall_F1 = test_f1\n",
    "full_accuracy = test_accuracy\n",
    "\n",
    "# Save final metrics\n",
    "output_file = os.path.join(output_dir, \"metrics.txt\")\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(f\"Overall F1 Score: {overall_F1:.4f}\\n\")\n",
    "    f.write(f\"Overall Accuracy: {overall_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Full Accuracy: {full_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Overall UAR: {overall_UAR:.4f}\\n\")\n",
    "    f.write(f\"Class Mapping :{label_mapping}\\n\")\n",
    "    f.write(f\" Best Epoch :{best_epoch}\\n\")\n",
    "    \n",
    "    f.write(f\"--------------PARAMETERS --------------\\n\")\n",
    "    f.write(f\"Pretrain Model :{pretrain_model}\\n\")\n",
    "    f.write(f\"Dataset Name: {dataset_name}\\n\")\n",
    "    f.write(f\"Class Weights :{class_weights}\\n\")\n",
    "    f.write(f\"Weight Decay: {training_args.weight_decay}\\n\")\n",
    "    f.write(f\"Model Type  CombinedModelsBi \\n\")\n",
    "    \n",
    "\n",
    "print(f\"Metrics saved to {output_file}\")\n",
    "\n",
    "inv_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e7b9c-058c-4577-9644-8e9d7681d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from datasets import DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "from functions_old import *\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    ViTForImageClassification,\n",
    "    BertModel,\n",
    "    AutoTokenizer,\n",
    "    get_scheduler,\n",
    "    DinatForImageClassification,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "# Load Best Model\n",
    "print(\"Loading best model for final evaluation.\")\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def collate_fn_test(examples):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle batching of image data and BERT inputs.\n",
    "    \"\"\"\n",
    "    # print(examples)\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"]\n",
    "                               for example in examples]).to(device)\n",
    "    input_ids = torch.stack([example[\"input_ids\"]\n",
    "                            for example in examples]).to(device)\n",
    "    attention_mask = torch.stack(\n",
    "        [example[\"attention_mask\"] for example in examples]).to(device)\n",
    "    files = [example[\"file\"] for example in examples]\n",
    "\n",
    "    bert_embeddings = torch.stack(\n",
    "        [example[\"bert_embeddings\"] for example in examples]).to(device)\n",
    "\n",
    "    return {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"files\": files,\n",
    "        \"bert_embeddings\": bert_embeddings\n",
    "    }\n",
    "\n",
    "# checkpoint_path = \"./DinatCurriculum/Regression/Valence/20250116_19/best_model.pt\"\n",
    "# output_dir = \"./DinatCurriculum/Regression/Valence/20250116_19/\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "dataset_name = 'cairocode/MSPP_TEST_MEL_6'\n",
    "# test_dataset = \n",
    "test_dataset = load_dataset(dataset_name)['test']\n",
    "\n",
    "test_dataset.set_transform(train_transforms)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=50,\n",
    "    collate_fn=collate_fn_test,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nStarting Test Evaluation...\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "all_test_predictions = []\n",
    "all_test_labels = []\n",
    "all_filenames = []  # To store filenames\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "    for batch in test_progress_bar:\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        # labels = batch[\"labels\"].float().to(device)\n",
    "\n",
    "        # Extract filenames from the batch (assuming \"filename\" is part of batch)\n",
    "        filenames = batch[\"files\"]  # Adjust key as necessary\n",
    "        all_filenames.extend(filenames)\n",
    "\n",
    "        outputs_dict = model(\n",
    "            pixel_values=pixel_values,\n",
    "            bert_input_ids=input_ids,\n",
    "            bert_attention_mask=attention_mask\n",
    "        )\n",
    "        predictions = outputs_dict[\"logits\"].argmax(dim=-1)  # Convert logits to class indices\n",
    "\n",
    "        # loss = criterion(predictions, labels)\n",
    "        # test_loss += loss.item()\n",
    "\n",
    "        all_test_predictions.extend(predictions.cpu().numpy())\n",
    "        # all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "# Correct the mapping logic\n",
    "# Ensure each prediction is converted to an integer before mapping\n",
    "mapped_labels = [label_mapping[int(pred)] for pred in all_test_predictions]\n",
    "\n",
    "output_csv_path = os.path.join(output_dir, \"test_predictions.csv\")\n",
    "with open(output_csv_path, mode=\"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"Filename\", \"Category\"])\n",
    "    for filename, prediction in zip(all_filenames, mapped_labels):\n",
    "        writer.writerow([filename, prediction])\n",
    "\n",
    "print(f\"Predictions saved to {output_csv_path}\")\n",
    "\n",
    "# print(dataset_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
