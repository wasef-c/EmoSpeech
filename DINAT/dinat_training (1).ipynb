{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d312506-4b7b-4a69-9850-5f56fd25f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/wasef-c/EmoSpeech.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc211f98-57f9-44ec-9022-a96c4b43e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers[torch] datasets scikit-learn matplotlib seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc02d993-0ad8-41e2-954a-80c57c527e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pillow\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f30c096-745c-4386-bd90-e97ca6a55bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install natten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600e7519-9e32-4df3-af64-06b0c1799a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "134c0009-6b3d-4290-8c84-5e3c9c5ec6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install natten==0.17.3+torch210cu118 -f https://shi-labs.com/natten/wheels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ba7905-f64e-4f3b-ae2f-2d74deb1974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece\n",
    "# !pip install googletrans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517657bf-f3f7-4b02-bcd2-419ff5ee0a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rml/Documents/pythontest/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "/home/rml/Documents/pythontest/.venv/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in dataset: {1, 3, 6, 10, 11, 12, 14, 15, 21, 24, 25, 26, 31, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 135, 136, 137, 139, 140, 142, 144, 145, 146, 147, 149, 154, 156, 157, 158, 161, 163, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 969, 970, 971, 972, 973, 974, 975, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1119, 1120, 1124, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1160, 1161, 1162, 1163, 1164, 1165, 1167, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1190, 1191, 1192, 1193, 1194, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1328, 1329, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1360, 1361, 1364, 1365, 1371, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1564, 1565, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1610, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1640, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1654, 1655, 1656, 1657, 1658, 1659, 1661, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1695, 1696, 1697, 1698, 1699, 1705, 1706, 1707, 1708, 1709, 1710, 1712, 1716, 1767, 1769, 1772, 1773, 1775, 1781, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1792, 1793, 1794, 1798, 1800, 1801, 1804, 1806, 1808, 1810, 1812, 1813, 1814, 1816, 1817, 1818, 1819, 1821, 1824, 1825, 1827, 1828, 1830, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1840, 1841, 1844, 1845, 1847, 1849, 1850, 1851, 1852, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1864, 1866, 1871, 1873, 1875, 1876, 1877, 1880, 1881, 1883, 1884, 1889, 1890, 1891, 1892, 1894, 1895, 1897, 1898, 1899, 1900, 1901, 1902, 1905, 1906, 1907, 1909, 1910, 1911, 1912, 1913, 1915, 1916, 1917, 1918, 1920, 1921, 1923, 1924, 1926, 1927, 1928, 1930, 1931, 1932, 1937, 1938, 1944, 1945, 1946, 1947, 1948, 1950, 1951, 1952, 1954, 1955, 1956, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1980, 1981, 1983, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1996, 1998, 1999, 2000, 2001, 2002, 2003, 2005, 2006, 2008, 2010, 2011, 2013, 2014, 2016, 2017, 2018, 2019, 2021, 2022, 2024, 2025, 2027, 2028, 2029, 2031, 2035, 2037, 2039, 2044, 2045, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2056, 2058, 2059, 2060, 2061, 2063, 2064, 2065, 2066, 2069, 2070, 2071, 2073, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2086, 2087, 2091, 2092, 2093, 2095, 2096, 2097, 2098, 2099, 2101, 2102, 2103, 2104, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2124, 2125, 2127, 2129, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2142, 2143, 2144, 2146, 2151, 2153, 2155, 2158, 2159, 2160, 2161, 2163, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2178, 2179, 2180, 2181, 2182, 2184, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2197, 2198, 2199, 2200, 2201, 2204, 2207, 2209, 2211, 2213, 2214, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2228, 2230, 2231, 2232, 2233, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2256, 2257, 2259, 2260, 2261, 2262, 2263, 2264, 2266, 2268, 2269, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2557, 2561, 2563, 2564, 2565, 2566, 2567, 2569, 2570, 2571, 2572, 2573, 2575, 2576, 2577, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2588, 2589, 2590, 2592, 2594, 2595, 2597, 2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2607, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2636, 2637, 2638, 2639, 2641, 2642, 2644, 2645, 2646, 2647, 2648, 2649, 2650, 2651, 2652, 2654, 2655, 2656, 2657, 2658, 2661, 2662, 2663, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2674, 2675, 2676, 2677, 2678, 2679, 2680, 2681, 2683, 2684, 2685, 2686, 2687, 2688, 2689, 2690, 2691, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2701, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2710, 2711, 2712, 2713, 2714, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723, 2724, 2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735, 2736, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2745, 2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767, 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2780, 2781, 2782, 2783, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2843, 2844, 2845, 2846, 2847, 2848, 2849, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 2859, 2861, 2862, 2863, 2864, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2872, 2873, 2874, 2875, 2877, 2878, 2879, 2880, 2881, 2882, 2884, 2885, 2886, 2887, 2889, 2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905, 2906, 2907, 2909, 2910, 2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919, 2920, 2921, 2922, 2923, 2924, 2925, 2926, 2927, 2928, 2929, 2930, 2931, 2932, 2933, 2934, 2935, 2936, 2937, 2938, 2939, 2940, 2941, 2942, 2943, 2944, 2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2966, 2967, 2968, 2969, 2970, 2971, 2972, 2973, 2976, 2978, 2979, 2980, 2981, 2982, 2983, 2984, 2985, 2986, 2987, 2988, 2989, 2990, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3109, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144, 3145, 3146, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3159, 3160, 3161, 3162, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3173, 3174, 3175, 3177, 3178, 3179, 3180, 3181, 3182, 3184, 3185, 3186, 3187, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3217, 3218, 3219, 3220, 3221, 3222, 3223, 3224, 3225, 3226, 3227, 3228, 3229, 3230, 3231, 3232, 3233, 3234, 3235, 3236, 3237, 3238, 3239, 3240, 3241, 3242, 3243, 3244, 3245, 3246, 3247, 3248, 3249, 3250, 3251, 3252, 3253, 3254, 3255, 3256, 3257, 3258, 3259, 3260, 3261, 3262, 3263, 3264, 3265, 3266, 3267, 3268, 3269, 3270, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3308, 3309, 3310, 3311, 3312, 3313, 3314, 3315, 3316, 3317, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3325, 3326, 3327, 3328, 3330, 3331, 3332}\n",
      "Unique labels in train_dataset: {10, 26, 31, 38, 50, 51, 68, 70, 71, 73, 74, 76, 77, 78, 79, 82, 83, 86, 87, 89, 90, 97, 99, 100, 101, 102, 107, 108, 109, 110, 111, 114, 118, 119, 120, 121, 124, 125, 128, 137, 140, 142, 144, 145, 146, 147, 149, 154, 156, 158, 161, 163, 165, 168, 172, 173, 176, 177, 178, 180, 181, 182, 189, 190, 191, 193, 194, 196, 198, 200, 203, 210, 212, 215, 217, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 231, 232, 233, 234, 237, 240, 241, 242, 243, 244, 245, 246, 247, 249, 252, 253, 254, 255, 256, 258, 259, 260, 261, 263, 264, 265, 267, 268, 269, 271, 272, 274, 277, 278, 279, 281, 284, 285, 286, 288, 289, 290, 291, 292, 293, 294, 295, 296, 298, 300, 303, 304, 305, 306, 307, 308, 310, 311, 312, 313, 314, 315, 317, 319, 320, 322, 323, 324, 325, 326, 327, 328, 330, 331, 335, 336, 337, 338, 339, 341, 343, 344, 346, 348, 352, 356, 357, 358, 359, 360, 361, 364, 365, 366, 368, 369, 371, 372, 374, 378, 379, 380, 381, 383, 384, 385, 388, 390, 391, 395, 398, 401, 402, 403, 404, 405, 407, 410, 411, 412, 413, 415, 416, 421, 423, 424, 426, 427, 428, 430, 431, 432, 434, 435, 436, 437, 438, 440, 441, 444, 447, 449, 451, 452, 454, 455, 457, 458, 459, 460, 461, 462, 463, 464, 466, 467, 469, 470, 471, 472, 473, 475, 476, 477, 479, 481, 482, 484, 486, 487, 488, 489, 491, 492, 493, 494, 495, 496, 498, 499, 502, 503, 507, 508, 510, 511, 513, 514, 519, 520, 522, 524, 525, 526, 530, 531, 532, 534, 535, 537, 540, 541, 542, 545, 546, 547, 548, 549, 552, 554, 556, 559, 560, 561, 562, 563, 564, 567, 572, 574, 575, 576, 579, 583, 584, 585, 586, 587, 589, 590, 592, 593, 596, 597, 598, 599, 600, 601, 604, 605, 607, 608, 609, 612, 614, 615, 616, 618, 619, 620, 622, 624, 625, 626, 627, 629, 631, 634, 635, 639, 640, 641, 642, 644, 645, 646, 648, 649, 650, 651, 653, 655, 657, 659, 660, 661, 666, 667, 669, 670, 671, 673, 674, 675, 676, 677, 679, 681, 682, 683, 685, 686, 687, 690, 694, 695, 697, 698, 699, 700, 701, 702, 704, 705, 706, 708, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 728, 729, 730, 731, 732, 734, 735, 736, 739, 740, 741, 742, 743, 745, 748, 751, 752, 753, 754, 756, 761, 762, 763, 764, 765, 767, 769, 772, 774, 775, 776, 780, 781, 782, 784, 786, 787, 788, 789, 791, 795, 797, 799, 803, 806, 808, 811, 815, 816, 818, 819, 820, 821, 822, 823, 824, 825, 827, 829, 831, 832, 833, 835, 836, 837, 838, 839, 840, 841, 842, 844, 845, 848, 849, 850, 852, 853, 855, 856, 857, 858, 861, 862, 863, 864, 865, 866, 869, 870, 871, 872, 873, 874, 877, 878, 879, 880, 882, 883, 885, 886, 888, 889, 890, 891, 893, 894, 895, 896, 897, 899, 900, 901, 902, 903, 905, 906, 907, 908, 911, 913, 914, 915, 918, 922, 924, 925, 926, 927, 928, 929, 934, 935, 936, 939, 940, 941, 942, 944, 945, 946, 947, 948, 949, 950, 952, 955, 957, 958, 959, 960, 963, 964, 965, 967, 969, 972, 974, 978, 979, 980, 981, 982, 983, 986, 987, 988, 991, 993, 994, 995, 996, 997, 998, 1000, 1004, 1007, 1008, 1010, 1011, 1013, 1014, 1016, 1018, 1020, 1021, 1024, 1026, 1027, 1028, 1029, 1030, 1032, 1036, 1038, 1039, 1044, 1046, 1051, 1052, 1053, 1054, 1055, 1056, 1059, 1060, 1061, 1062, 1063, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1079, 1080, 1083, 1084, 1085, 1093, 1094, 1096, 1097, 1098, 1099, 1100, 1119, 1120, 1142, 1143, 1144, 1145, 1146, 1148, 1149, 1150, 1151, 1161, 1162, 1167, 1180, 1181, 1183, 1184, 1185, 1186, 1187, 1190, 1191, 1192, 1193, 1194, 1202, 1205, 1206, 1207, 1210, 1213, 1214, 1215, 1216, 1218, 1220, 1222, 1223, 1231, 1232, 1234, 1235, 1236, 1237, 1239, 1241, 1243, 1262, 1263, 1290, 1291, 1292, 1294, 1296, 1297, 1299, 1300, 1308, 1309, 1311, 1312, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1347, 1348, 1349, 1351, 1353, 1354, 1360, 1376, 1377, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1390, 1392, 1393, 1394, 1395, 1401, 1402, 1403, 1404, 1407, 1408, 1410, 1412, 1413, 1414, 1417, 1423, 1424, 1425, 1427, 1429, 1430, 1431, 1433, 1439, 1440, 1441, 1443, 1444, 1445, 1448, 1449, 1452, 1454, 1455, 1456, 1458, 1459, 1468, 1469, 1471, 1473, 1475, 1476, 1478, 1479, 1480, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1493, 1507, 1508, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1521, 1522, 1523, 1524, 1526, 1533, 1535, 1536, 1538, 1545, 1546, 1564, 1571, 1573, 1575, 1577, 1578, 1579, 1580, 1582, 1583, 1584, 1585, 1586, 1590, 1591, 1595, 1596, 1597, 1599, 1602, 1603, 1604, 1606, 1608, 1610, 1612, 1613, 1614, 1615, 1617, 1618, 1621, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1634, 1635, 1637, 1638, 1640, 1643, 1646, 1647, 1648, 1649, 1650, 1651, 1654, 1656, 1658, 1663, 1665, 1667, 1668, 1669, 1670, 1671, 1672, 1675, 1677, 1682, 1683, 1685, 1686, 1689, 1695, 1696, 1697, 1698, 1706, 1707, 1708, 1709, 1710, 1712, 1716, 1769, 1772, 1775, 1781, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1792, 1798, 1800, 1804, 1806, 1810, 1812, 1813, 1814, 1816, 1818, 1819, 1824, 1825, 1827, 1828, 1836, 1838, 1841, 1845, 1847, 1850, 1857, 1858, 1859, 1891, 1895, 1898, 1900, 1902, 1905, 1906, 1910, 1911, 1913, 1915, 1918, 1920, 1923, 1931, 1937, 1938, 1945, 1946, 1947, 1948, 1950, 1951, 1952, 1954, 1955, 1962, 1963, 1964, 1965, 1966, 1967, 1969, 1970, 1971, 1972, 1973, 1975, 1976, 1985, 1987, 1988, 1989, 1990, 1992, 1996, 1999, 2000, 2001, 2002, 2003, 2005, 2006, 2011, 2016, 2017, 2018, 2021, 2025, 2027, 2028, 2031, 2035, 2037, 2039, 2044, 2047, 2048, 2049, 2050, 2051, 2056, 2058, 2063, 2066, 2069, 2070, 2071, 2076, 2077, 2087, 2091, 2093, 2095, 2096, 2098, 2103, 2182, 2190, 2192, 2199, 2204, 2207, 2209, 2211, 2213, 2214, 2219, 2228, 2232, 2235, 2239, 2241, 2243, 2247, 2248, 2250, 2254, 2257, 2259, 2261, 2263, 2271, 2274, 2275, 2284, 2285, 2289, 2291, 2292, 2293, 2295, 2300, 2307, 2310, 2314, 2315, 2317, 2318, 2324, 2325, 2326, 2331, 2332, 2333, 2334, 2336, 2339, 2343, 2345, 2346, 2347, 2350, 2351, 2352, 2354, 2355, 2357, 2358, 2360, 2362, 2365, 2366, 2372, 2379, 2380, 2382, 2384, 2385, 2386, 2388, 2389, 2393, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2404, 2405, 2406, 2408, 2409, 2411, 2415, 2417, 2419, 2422, 2423, 2425, 2426, 2432, 2433, 2435, 2436, 2439, 2442, 2445, 2447, 2448, 2450, 2451, 2452, 2455, 2456, 2458, 2462, 2463, 2466, 2472, 2474, 2480, 2482, 2483, 2485, 2486, 2487, 2491, 2493, 2495, 2496, 2498, 2499, 2513, 2514, 2517, 2518, 2519, 2521, 2523, 2524, 2525, 2526, 2528, 2529, 2532, 2534, 2535, 2539, 2541, 2544, 2545, 2546, 2547, 2549, 2550, 2551, 2557, 2563, 2564, 2565, 2566, 2567, 2570, 2575, 2583, 2590, 2592, 2595, 2597, 2598, 2599, 2602, 2604, 2607, 2614, 2616, 2618, 2621, 2622, 2624, 2626, 2630, 2633, 2634, 2637, 2638, 2645, 2646, 2647, 2655, 2656, 2657, 2658, 2661, 2662, 2663, 2664, 2666, 2668, 2669, 2670, 2676, 2680, 2683, 2684, 2686, 2688, 2689, 2691, 2693, 2694, 2695, 2696, 2698, 2701, 2702, 2703, 2706, 2707, 2709, 2711, 2712, 2713, 2714, 2718, 2719, 2720, 2721, 2722, 2723, 2724, 2725, 2726, 2728, 2729, 2731, 2732, 2733, 2734, 2735, 2736, 2741, 2742, 2745, 2752, 2753, 2754, 2755, 2756, 2758, 2760, 2761, 2763, 2764, 2768, 2769, 2770, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2780, 2783, 2788, 2792, 2793, 2794, 2796, 2797, 2798, 2799, 2802, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2816, 2818, 2819, 2820, 2822, 2824, 2825, 2826, 2827, 2829, 2830, 2831, 2832, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2844, 2845, 2846, 2853, 2854, 2855, 2856, 2857, 2858, 2859, 2861, 2863, 2864, 2867, 2869, 2870, 2871, 2872, 2873, 2874, 2877, 2878, 2879, 2882, 2885, 2887, 2889, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2900, 2901, 2903, 2904, 2905, 2911, 2912, 2916, 2917, 2918, 2919, 2920, 2922, 2923, 2924, 2925, 2927, 2928, 2929, 2930, 2931, 2932, 2933, 2934, 2936, 2937, 2938, 2939, 2940, 2942, 2943, 2944, 2946, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2967, 2968, 2969, 2970, 2971, 2973, 2976, 2978, 2979, 2980, 2981, 2982, 2983, 2985, 2986, 2988, 2989, 3003, 3004, 3006, 3008, 3009, 3010, 3011, 3012, 3013, 3016, 3021, 3023, 3024, 3025, 3027, 3028, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3041, 3042, 3043, 3045, 3046, 3048, 3052, 3055, 3056, 3061, 3062, 3063, 3064, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3082, 3083, 3085, 3087, 3090, 3091, 3094, 3095, 3096, 3104, 3105, 3106, 3109, 3111, 3112, 3114, 3116, 3118, 3122, 3123, 3124, 3126, 3128, 3129, 3130, 3133, 3134, 3137, 3138, 3140, 3141, 3142, 3144, 3148, 3152, 3154, 3160, 3162, 3164, 3166, 3169, 3170, 3173, 3174, 3175, 3177, 3178, 3182, 3184, 3187, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3197, 3199, 3200, 3201, 3202, 3203, 3204, 3207, 3210, 3211, 3212, 3213, 3214, 3215, 3218, 3219, 3223, 3225, 3226, 3228, 3229, 3231, 3232, 3233, 3234, 3236, 3239, 3240, 3243, 3244, 3245, 3246, 3247, 3248, 3250, 3253, 3254, 3255, 3256, 3259, 3261, 3262, 3265, 3266, 3267, 3268, 3269, 3270, 3272, 3273, 3274, 3276, 3277, 3279, 3280, 3281, 3282, 3283, 3286, 3288, 3289, 3291, 3294, 3295, 3297, 3298, 3299, 3300, 3304, 3305, 3306, 3307, 3308, 3310, 3311, 3314, 3315, 3316, 3318, 3319, 3320, 3321, 3324, 3325, 3327, 3328, 3330}\n",
      "OrderedDict([(3, (0, 197)), (25, (197, 418)), (52, (418, 799)), (58, (799, 928)), (104, (928, 957)), (105, (957, 1256)), (106, (1256, 1408)), (122, (1408, 1427)), (126, (1427, 1454)), (139, (1454, 1685)), (171, (1685, 1737)), (183, (1737, 1776)), (208, (1776, 1819)), (235, (1819, 1833)), (248, (1833, 1835)), (251, (1835, 1838)), (257, (1838, 1840)), (266, (1840, 1853)), (273, (1853, 1872)), (275, (1872, 1877)), (280, (1877, 1886)), (282, (1886, 2363)), (301, (2363, 2424)), (329, (2424, 2508)), (370, (2508, 2512)), (373, (2512, 2725)), (389, (2725, 2734)), (393, (2734, 2755)), (418, (2755, 2764)), (419, (2764, 2770)), (429, (2770, 2772)), (442, (2772, 2788)), (456, (2788, 2791)), (465, (2791, 2798)), (478, (2798, 2807)), (512, (2807, 2965)), (518, (2965, 2985)), (527, (2985, 2995)), (543, (2995, 3025)), (553, (3025, 3037)), (557, (3037, 3064)), (568, (3064, 3074)), (570, (3074, 3079)), (573, (3079, 3088)), (581, (3088, 3104)), (582, (3104, 3123)), (595, (3123, 3125)), (602, (3125, 3137)), (603, (3137, 3145)), (610, (3145, 3161)), (611, (3161, 3162)), (621, (3162, 3165)), (623, (3165, 3178)), (628, (3178, 3181)), (632, (3181, 3182)), (638, (3182, 3216)), (652, (3216, 3227)), (654, (3227, 3228)), (678, (3228, 3244)), (680, (3244, 3258)), (684, (3258, 3280)), (689, (3280, 3288)), (691, (3288, 3294)), (703, (3294, 3297)), (709, (3297, 3302)), (727, (3302, 3318)), (733, (3318, 3322)), (737, (3322, 3331)), (738, (3331, 3349)), (744, (3349, 3355)), (757, (3355, 3360)), (759, (3360, 3380)), (773, (3380, 3382)), (778, (3382, 3384)), (783, (3384, 3386)), (792, (3386, 3389)), (794, (3389, 3411)), (801, (3411, 3412)), (812, (3412, 3542)), (813, (3542, 3609)), (814, (3609, 3618)), (817, (3618, 4096)), (847, (4096, 4122)), (875, (4122, 4125)), (909, (4125, 4156)), (919, (4156, 4247)), (930, (4247, 4270)), (932, (4270, 4308)), (933, (4308, 4373)), (943, (4373, 4432)), (962, (4432, 4509)), (966, (4509, 4573)), (970, (4573, 4613)), (973, (4613, 4615)), (989, (4615, 4764)), (990, (4764, 4823)), (992, (4823, 4849)), (1001, (4849, 4939)), (1002, (4939, 5190)), (1005, (5190, 5288)), (1025, (5288, 5347)), (1034, (5347, 5378)), (1043, (5378, 5409)), (1049, (5409, 5415)), (1050, (5415, 5441)), (1057, (5441, 5505)), (1065, (5505, 5552)), (1075, (5552, 5587)), (1076, (5587, 5596)), (1078, (5596, 5602)), (1095, (5602, 5609)), (1101, (5609, 5616)), (1104, (5616, 5638)), (1124, (5638, 5654)), (1160, (5654, 5655)), (1163, (5655, 5657)), (1164, (5657, 5667)), (1178, (5667, 5671)), (1201, (5671, 5675)), (1203, (5675, 5678)), (1208, (5678, 5680)), (1221, (5680, 5722)), (1293, (5722, 5757)), (1298, (5757, 5801)), (1313, (5801, 5811)), (1346, (5811, 6202)), (1352, (6202, 6366)), (1375, (6366, 6367)), (1378, (6367, 6369)), (1415, (6369, 6467)), (1420, (6467, 6520)), (1422, (6520, 6847)), (1428, (6847, 6962)), (1438, (6962, 7164)), (1442, (7164, 7256)), (1457, (7256, 7257)), (1467, (7257, 7314)), (1470, (7314, 7396)), (1482, (7396, 7416)), (1492, (7416, 7484)), (1518, (7484, 7535)), (1519, (7535, 7573)), (1532, (7573, 7606)), (1549, (7606, 7609)), (1587, (7609, 7623)), (1598, (7623, 7844)), (1616, (7844, 7895)), (1623, (7895, 7983)), (1633, (7983, 8010)), (1636, (8010, 8056)), (1645, (8056, 8123)), (1655, (8123, 8154)), (1661, (8154, 8277)), (1664, (8277, 8313)), (1673, (8313, 8318)), (1681, (8318, 8491)), (1688, (8491, 8534)), (1705, (8534, 8537)), (1773, (8537, 8540)), (1801, (8540, 8748)), (1808, (8748, 8749)), (1817, (8749, 9997)), (1821, (9997, 10279)), (1837, (10279, 10434)), (1851, (10434, 10534)), (1852, (10534, 10604)), (1853, (10604, 10677)), (1855, (10677, 10704)), (1856, (10704, 10716)), (1894, (10716, 10882)), (1897, (10882, 11051)), (1901, (11051, 11071)), (1907, (11071, 11175)), (1916, (11175, 11537)), (1921, (11537, 11598)), (1926, (11598, 11697)), (1958, (11697, 11722)), (1974, (11722, 11732)), (1977, (11732, 11735)), (1980, (11735, 11741)), (1981, (11741, 11743)), (1983, (11743, 11745)), (2014, (11745, 11824)), (2045, (11824, 11867)), (2061, (11867, 11871)), (2064, (11871, 11873)), (2065, (11873, 11874)), (2080, (11874, 11950)), (2216, (11950, 11980)), (2220, (11980, 12091)), (2226, (12091, 12096)), (2246, (12096, 12098)), (2253, (12098, 12099)), (2266, (12099, 12101)), (2269, (12101, 12124)), (2278, (12124, 12223)), (2279, (12223, 12233)), (2281, (12233, 12242)), (2283, (12242, 12245)), (2286, (12245, 12248)), (2287, (12248, 12252)), (2290, (12252, 12256)), (2311, (12256, 12285)), (2328, (12285, 12313)), (2329, (12313, 12322)), (2335, (12322, 12327)), (2341, (12327, 12359)), (2361, (12359, 12376)), (2364, (12376, 12385)), (2390, (12385, 12390)), (2407, (12390, 12423)), (2427, (12423, 12429)), (2434, (12429, 12433)), (2440, (12433, 12437)), (2470, (12437, 12457)), (2484, (12457, 12487)), (2530, (12487, 12506)), (2531, (12506, 12515)), (2540, (12515, 12573)), (2561, (12573, 12642)), (2585, (12642, 12669)), (2589, (12669, 12689)), (2594, (12689, 12768)), (2632, (12768, 12797)), (2717, (12797, 12805)), (2739, (12805, 12846)), (2751, (12846, 12850)), (2782, (12850, 12882)), (2785, (12882, 12981)), (2786, (12981, 12990)), (2795, (12990, 13011)), (2801, (13011, 13013)), (2843, (13013, 13016)), (2847, (13016, 13017)), (2865, (13017, 13025)), (2866, (13025, 13028)), (2875, (13028, 13034)), (2881, (13034, 13043)), (2899, (13043, 13056)), (2902, (13056, 13064)), (2906, (13064, 13105)), (2914, (13105, 13118)), (2915, (13118, 13122)), (2935, (13122, 13123)), (3005, (13123, 13124)), (3017, (13124, 13130)), (3020, (13130, 13134)), (3040, (13134, 13241)), (3059, (13241, 13246)), (3069, (13246, 13266)), (3070, (13266, 13277)), (3081, (13277, 13305)), (3088, (13305, 13307)), (3092, (13307, 13333)), (3093, (13333, 13347)), (3097, (13347, 13369)), (3098, (13369, 13382)), (3100, (13382, 13395)), (3115, (13395, 13405)), (3117, (13405, 13408)), (3120, (13408, 13410)), (3149, (13410, 13424)), (3155, (13424, 13454)), (3161, (13454, 13476)), (3167, (13476, 13477)), (3198, (13477, 13489)), (3216, (13489, 13496)), (3217, (13496, 13502)), (3222, (13502, 13507)), (3224, (13507, 13646)), (3230, (13646, 13654)), (3237, (13654, 13661)), (3241, (13661, 13668)), (3249, (13668, 13676)), (3258, (13676, 13681)), (3260, (13681, 13682)), (3263, (13682, 13683)), (3264, (13683, 13686)), (3293, (13686, 13770)), (3317, (13770, 13773)), (3323, (13773, 13785)), (3331, (13785, 13849))])\n",
      "Class distribution before balancing:\n",
      "Per-label target size: 0\n",
      "Test dataset size: 20976\n",
      "Train dataset size: 71377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DinatForImageClassification were not initialized from the model checkpoint at shi-labs/dinat-mini-in1k-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([2826, 512]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2826]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_53629/989050676.py:312: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n",
      "/home/rml/Documents/pythontest/.venv/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "                                                    \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "weight tensor should be defined either for all 2826 classes or no classes but got weight tensor of shape: [3331]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 429\u001b[0m\n\u001b[1;32m    426\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    427\u001b[0m features \u001b[38;5;241m=\u001b[39m  outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcombined_features\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 429\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcecc_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# loss = focal_loss(logits, labels)\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# focal_loss = AdaptiveLearnableFocalLoss_V2(num_classes = num_labels, class_weights = class_weights)\u001b[39;00m\n\u001b[1;32m    435\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Documents/pythontest/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/pythontest/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/pythontest/EmoSpeech/DINAT/functionsV3.py:1380\u001b[0m, in \u001b[0;36mBalancedCrossEntropyWithContrastiveLoss.forward\u001b[0;34m(self, logits, combined_features, targets)\u001b[0m\n\u001b[1;32m   1378\u001b[0m     class_weights \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (class_counts \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m   1379\u001b[0m     class_weights \u001b[38;5;241m=\u001b[39m class_weights \u001b[38;5;241m/\u001b[39m class_weights\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes\n\u001b[0;32m-> 1380\u001b[0m     ce_loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;66;03m# 2. Enhanced Contrastive-Center Loss\u001b[39;00m\n\u001b[1;32m   1383\u001b[0m centers_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcenters[targets]\n",
      "File \u001b[0;32m~/Documents/pythontest/.venv/lib/python3.10/site-packages/torch/nn/functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: weight tensor should be defined either for all 2826 classes or no classes but got weight tensor of shape: [3331]"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "#BEST SO FAR: 20250128_14\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import random\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    DinatForImageClassification,\n",
    "    TrainingArguments,\n",
    "    get_scheduler,\n",
    "    BertModel,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "# Hugging Face Datasets\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "# Data processing and metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.auto import tqdm\n",
    "best_epoch = 0\n",
    "# Custom functions (from your own module)\n",
    "from functionsV3 import *\n",
    "import numpy as np\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "# label_mapping = {\n",
    "#     0: 'C',\n",
    "#     1: 'N',\n",
    "#     2: 'H',\n",
    "#     3: 'S',\n",
    "#     4: 'U',\n",
    "#     5: 'F',\n",
    "#     6: 'A',\n",
    "#     7: 'D'\n",
    "# }\n",
    "\n",
    "# label_mapping = {\n",
    "#     0: 'Male',\n",
    "#     1: 'Female',\n",
    "#     # 2: 'H',\n",
    "#     # 3: 'S',\n",
    "#     # 4: 'U',\n",
    "#     # 5: 'F',\n",
    "#     # 6: 'A',\n",
    "#     # 7: 'D'\n",
    "# }\n",
    "base_column  = \"SpkrID\"\n",
    "#{0: 'C', 1: 'N', 2: 'H', 3: 'S', 4: 'U', 5: 'F', 6: 'A', 7: 'D'}\n",
    "# Directories and Model Config\n",
    "base_dir = \"/home/rml/Documents/pythontest/Trained_Models/curr/spkr\"\n",
    "output_dir = create_unique_output_dir(base_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "DATASET_PATH = \"../data\"\n",
    "# CHECKPOINT_PATH = \"./NLPIMG_Model_001\"\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = \"shi-labs/dinat-mini-in1k-224\"  # For processor loading if needed\n",
    "checkpoint_path = \"/home/rml/Documents/pythontest/Trained_Models/curr/gender/20250224_5/best_model.pt\" #None #\"./EmoDom/best_model.pt\"\n",
    "# checkpoint_path = \"./DinatMEL/20250126_3/best_model.pt\"\n",
    "# checkpoint_path = \"./DinatMEL/20250125_1/best_model.pt\"\n",
    "pretrain_model = model_path\n",
    "bert_model_name = \"bert-base-uncased\"\n",
    "BATCH_SIZE = 45\n",
    "\n",
    "# Load Dataset\n",
    "dataset_name = \"cairocode/MSPP_MEL_6\"\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "unique_labels = set(dataset['train'][base_column])\n",
    "print(\"Unique labels in dataset:\", unique_labels)\n",
    "\n",
    "label_mapping = {label: i for i, label in enumerate(sorted(unique_labels))}\n",
    "# Reverse the mapping for efficient lookup\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "num_labels = len(label_mapping)\n",
    "\n",
    "# Define a filtering function\n",
    "def is_mappable(example):\n",
    "    return example[base_column] in reverse_label_mapping\n",
    "\n",
    "column  = \"label\"\n",
    "\n",
    "# Filter out rows with unmappable values\n",
    "filtered_dataset = dataset.filter(is_mappable)\n",
    "\n",
    "# Map the filtered dataset to add the new column\n",
    "filtered_dataset = filtered_dataset.map(lambda x: {\"label\": reverse_label_mapping[x[base_column]]})\n",
    "\n",
    "\n",
    "# Define a filtering function\n",
    "def is_valid_transcript(example):\n",
    "    return isinstance(example['transcript'], str)\n",
    "\n",
    "\n",
    "# Filter out non-string transcripts in each split\n",
    "filtered_dataset = filtered_dataset.filter(is_valid_transcript)\n",
    "\n",
    "inv_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Step 2: Specify an order for the numeric labels\n",
    "# ordered_labels_numeric = [0, 1] #, 2, 3, 4, 5, 6, 7 ]#, 7]\n",
    "ordered_labels_str = sorted(label_mapping.values())\n",
    "\n",
    "\n",
    "# all_test_labels = [...]\n",
    "# all_test_predictions = [...]\n",
    "\n",
    "# Step 3: Generate the confusion matrix\n",
    "\n",
    "train_test_split = filtered_dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# train_val_split = train_test_split['train'].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# train_dataset = train_val_split['test']\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "unique_speakers = set(filtered_dataset['train']['SpkrID'])\n",
    "shuffled_speakers = list(unique_speakers)\n",
    "random.shuffle(shuffled_speakers)\n",
    "\n",
    "# Split speakers into 80% (train+val) and 20% (test)\n",
    "split_idx = int(len(shuffled_speakers) * 0.8)\n",
    "train_val_speakers = shuffled_speakers[:split_idx]\n",
    "test_speakers = shuffled_speakers[split_idx:]\n",
    "\n",
    "# Split the train_val set into 85% train and 15% validation\n",
    "train_val_split_idx = int(len(train_val_speakers) * 0.85)\n",
    "train_speakers = train_val_speakers[:train_val_split_idx]\n",
    "val_speakers = train_val_speakers[train_val_split_idx:]\n",
    "\n",
    "# Filter the dataset based on speaker IDs\n",
    "train_dataset = filtered_dataset['train'].filter(lambda example: example['SpkrID'] in train_speakers)\n",
    "val_dataset = filtered_dataset['train'].filter(lambda example: example['SpkrID'] in val_speakers)\n",
    "test_dataset = filtered_dataset['train'].filter(lambda example: example['SpkrID'] in test_speakers)\n",
    "\n",
    "\n",
    "# Assuming the labels are stored in the 'label' column\n",
    "unique_labels = set(train_dataset['label'])\n",
    "print(\"Unique labels in train_dataset:\", unique_labels)\n",
    "# Sort the train dataset by the 'label' column\n",
    "test_dataset = train_test_split['test']\n",
    "\n",
    "sorted_train = train_dataset.sort(\"label\")\n",
    "# label_boundaries = get_label_boundaries(sorted_train, \"label\")\n",
    "# print(label_boundaries)\n",
    "# # Print the class distribution before balancing using label boundaries\n",
    "# # Initialize the count array with zeros\n",
    "# count = np.zeros((num_labels,), dtype=int)\n",
    "\n",
    "# print(\"Class distribution before balancing:\")\n",
    "\n",
    "# # Assuming label_boundaries is a dictionary like {0: (0, 50), 1: (51, 100), ...}\n",
    "# for lbl, (start, end) in label_boundaries.items():\n",
    "#     count[lbl] = end - start\n",
    "#     print(f\"Label {lbl}: {count[lbl]} samples\")\n",
    "\n",
    "# # Calculate the average target size per class\n",
    "# avg_count = int(np.mean(count))\n",
    "# print(\"Per-label target size:\", avg_count)\n",
    "\n",
    "\n",
    "# # Balance the dataset\n",
    "# balanced_train_dataset = balance_dataset_by_sort(\n",
    "#     sorted_train,\n",
    "#     label_boundaries,\n",
    "#     avg_count,\n",
    "#     label_column=\"label\",\n",
    "#     seed=42\n",
    "# )\n",
    "# balanced_train_dataset = train_dataset\n",
    "\n",
    "# # Compute new label boundaries for the balanced dataset\n",
    "# balanced_label_boundaries = get_label_boundaries(\n",
    "#     balanced_train_dataset.sort(\"label\"),\n",
    "#     \"label\"\n",
    "# )\n",
    "\n",
    "# # Print the class distribution after balancing\n",
    "# print(\"\\nClass distribution after balancing:\")\n",
    "# for lbl, (start, end) in balanced_label_boundaries.items():\n",
    "#     count = end - start\n",
    "#     print(f\"Label {lbl}: {count} samples\")\n",
    "\n",
    "# # Final size of the balanced dataset\n",
    "# print(\"\\nFinal balanced training size:\", len(balanced_train_dataset))\n",
    "\n",
    "\n",
    "balanced_train_dataset = train_dataset\n",
    "sorted_val = val_dataset.sort(\"label\")\n",
    "label_boundaries = get_label_boundaries(sorted_val, \"label\")\n",
    "print(label_boundaries)\n",
    "# Print the class distribution before balancing using label boundaries\n",
    "# Initialize the count array with zeros\n",
    "count = np.zeros((num_labels,), dtype=int)\n",
    "\n",
    "print(\"Class distribution before balancing:\")\n",
    "\n",
    "# # Assuming label_boundaries is a dictionary like {0: (0, 50), 1: (51, 100), ...}\n",
    "# for lbl, (start, end) in label_boundaries.items():\n",
    "#     count[lbl] = end - start\n",
    "#     # print(f\"Label {lbl}: {count[lbl]} samples\")\n",
    "\n",
    "# Calculate the average target size per class\n",
    "avg_count = int(np.mean(count))\n",
    "print(\"Per-label target size:\", avg_count)\n",
    "\n",
    "\n",
    "# # Balance the dataset\n",
    "# balanced_val_dataset = balance_dataset_by_sort(\n",
    "#     sorted_val,\n",
    "#     label_boundaries,\n",
    "#     avg_count,\n",
    "#     label_column=\"label\",\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "# val_dataset = balanced_val_dataset\n",
    "\n",
    "print(\"Test dataset size:\", len(test_dataset))\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "\n",
    "class_weights = calculate_class_weights(\n",
    "    train_dataset)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "# class_weoghts = torch(ones)\n",
    "# Transforms (assumed imported from functions_old)\n",
    "balanced_train_dataset.set_transform(train_transforms)\n",
    "train_dataset.set_transform(train_transforms)\n",
    "val_dataset.set_transform(val_transforms)\n",
    "test_dataset.set_transform(val_transforms)\n",
    "\n",
    "train_sampler = CustomSampler(train_dataset)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    balanced_train_dataset,\n",
    "    # sampler=train_sampler,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda examples: collate_fn_reg(examples, column=column),\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=lambda examples: collate_fn_reg(examples, column=column),\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=lambda examples: collate_fn_reg(examples, column=column),\n",
    ")\n",
    "\n",
    "\n",
    "# Load Models\n",
    "image_model = DinatForImageClassification.from_pretrained(\n",
    "    pretrain_model,\n",
    "    num_labels=num_labels,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    problem_type=\"single_label_classification\",\n",
    ").to(device)\n",
    "\n",
    "processor = DinatForImageClassification.from_pretrained(model_path).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name).to(device)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Initialize the Combined Regression Model\n",
    "# ----------------------------------------------------------------------\n",
    "unfozen_layers = [10,11]\n",
    "next_layer_to_unfreeze = unfozen_layers[0]-1\n",
    " \n",
    "model = CombinedModelsBi(\n",
    "    image_model=image_model,\n",
    "    bert_model=bert_model,\n",
    "    image_feature_dim=512,\n",
    "    bert_embedding_dim=768,\n",
    "    combined_dim=512,\n",
    "    num_labels=num_labels,\n",
    "    unfrozen_layers = unfozen_layers\n",
    "\n",
    ").to(device)\n",
    "\n",
    "if checkpoint_path != None:\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    # # Define the keywords to include and exclude\n",
    "    include_keyword = \"model\"\n",
    "    exclude_keys = {\n",
    "        \"image_model.classifier.weight\",\n",
    "        \"image_model.classifier.bias\",\n",
    "        \"fc3\"\n",
    "    }\n",
    "\n",
    "    # Use dictionary comprehension to filter the keys\n",
    "    filtered_checkpoint = {\n",
    "        key: value for key, value in checkpoint.items()\n",
    "        if include_keyword in key and key not in exclude_keys\n",
    "    }\n",
    "    # Load the filtered state dict\n",
    "    # filtered_checkpoint = checkpoint\n",
    "    model.load_state_dict(filtered_checkpoint, strict=False)\n",
    "\n",
    "\n",
    "# model.load_state_dict(torch.load(\"/media/carol/Data/Documents/Emo_rec/Notebooks/DINAT_BERT/MSPP_COMP/20250105_11/best_model.pt\"))\n",
    "#Mapping of categories to integers: {'D': 0, 'H': 1, 'A': 2, 'O': 3, 'N': 4, 'C': 5, 'F': 6, 'S': 7}\n",
    "#Mapping of categories to integers: {'F': 0, 'O': 1, 'H': 2, 'D': 3, 'A': 4, 'S': 5, 'N': 6, 'C': 7}\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./logs\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "logging.getLogger().addHandler(logging.NullHandler())\n",
    "logging.getLogger(\"natten.functional\").setLevel(logging.ERROR)\n",
    "\n",
    "# Optimizer & Scheduler\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=training_args.learning_rate,\n",
    "    weight_decay=training_args.weight_decay\n",
    ")\n",
    "\n",
    "num_training_steps = len(train_loader) * training_args.num_train_epochs\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=training_args.warmup_steps,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "# focal_loss = AdaptiveLearnableFocalLoss(class_weights=class_weights)\n",
    "# focal_loss = AdaptiveLearnableFocalLoss()\n",
    "\n",
    "# focal_loss = AdaptiveLearnableFocalLoss_V2(num_classes = num_labels)\n",
    "# cecc_loss= CrossEntropyWithContrastiveCenterLoss(\n",
    "#     num_classes=8,  # Number of emotion classes\n",
    "#     feature_dim=512,  # Feature dimension from fc2\n",
    "#     alpha=1,  # Adjust weights for CE vs Contrastive-Center\n",
    "#     beta=0.2\n",
    "# )\n",
    "#1.0, beta=0.01\n",
    "cecc_loss= BalancedCrossEntropyWithContrastiveLoss(\n",
    "    num_classes=num_labels,  # Number of emotion classes\n",
    "    feature_dim=512,  # Feature dimension from fc2\n",
    "    alpha=1.5,  # Adjust weights for CE vs Contrastive-Center\n",
    "    beta=0.02,\n",
    "    gamma = 1\n",
    ")\n",
    "\n",
    "\n",
    "# BalancedCrossEntropyWithContrastiveLoss 0.01\n",
    "\n",
    "'''\n",
    "Start with alpha=0.5, beta=1.0, gamma=0.5\n",
    "If UAR is too low, increase alpha\n",
    "If STD is too high, increase gamma\n",
    "If classes are not well-separated, increase beta\n",
    "\n",
    "alpha=0.5, beta=1.0, gamma=0.5\n",
    "'''\n",
    "\n",
    "# Training Variables\n",
    "num_epochs = training_args.num_train_epochs\n",
    "patience = 12\n",
    "best_val_accuracy = 0\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses, val_losses, epochs_list = [], [], []\n",
    "\n",
    "best_model_path = os.path.join(output_dir, \"best_model.pt\")\n",
    "class_weights = None\n",
    "##############################################################################\n",
    "# Training Loop\n",
    "##############################################################################\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            pixel_values=pixel_values,\n",
    "            bert_input_ids=input_ids,\n",
    "            bert_attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs[\"logits\"]\n",
    "        features =  outputs[\"combined_features\"]\n",
    "\n",
    "        loss = cecc_loss(logits,features, labels)\n",
    "        # loss = focal_loss(logits, labels)\n",
    "\n",
    "        # focal_loss = AdaptiveLearnableFocalLoss_V2(num_classes = num_labels, class_weights = class_weights)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"Loss\": loss.item()})\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {avg_train_loss:.4f}\")\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_predictions, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                pixel_values=pixel_values,\n",
    "                bert_input_ids=input_ids,\n",
    "                bert_attention_mask=attention_mask\n",
    "            )\n",
    "            logits = outputs[\"logits\"]\n",
    "            features =  outputs[\"combined_features\"]\n",
    "\n",
    "            loss = cecc_loss(logits,features, labels)\n",
    "\n",
    "            # loss = focal_loss(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    uar = recall_score(all_labels, all_predictions, average=\"macro\")\n",
    "    f1 = f1_score(all_labels, all_predictions, average=\"macro\")\n",
    "    per_class_recall = recall_score(all_labels, all_predictions, average=None)\n",
    "    uar_std = np.std(per_class_recall)\n",
    "\n",
    "    gamma = 1.5\n",
    "    comparison_metric = uar / (1 + gamma * uar_std)\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    epochs_list.append(epoch + 1)\n",
    "\n",
    "    print(\n",
    "        f\"Validation Loss: {avg_val_loss:.4f}, \"\n",
    "        f\"Accuracy: {accuracy:.4f}, UAR: {uar:.4f}, F1: {f1:.4f}, UAR STD: {uar_std} \"\n",
    "        f\"\\nPer-class Recall: {per_class_recall}\"\n",
    "        f\"\\n Comparison metric: {comparison_metric}\"\n",
    "\n",
    "    )\n",
    "    plot_and_save_confusion_matrix(all_labels, all_predictions, ordered_labels_str, output_dir, epoch=epoch)\n",
    "\n",
    "\n",
    "    # Early Stopping based on Accuracy\n",
    "    if comparison_metric > best_val_accuracy:\n",
    "        best_val_accuracy = comparison_metric\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        torch.save(model.image_model.state_dict(), \"fine_tuned_image_model.pth\")\n",
    "        best_epoch = epoch\n",
    "        print(\"Validation uar improved. Best model saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    # epoch_dir = os.path.join(output_dir, f\"Epoch_{epoch}_model.pt\")\n",
    "    # torch.save(model.state_dict(), epoch_dir)\n",
    "\n",
    "    # import torch\n",
    "    \n",
    "    # epsilon = 0.1\n",
    "    # class_weights = [(1 - r) + epsilon for r in per_class_recall]\n",
    "    # class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    \n",
    "    # print(\"Computed class_weights:\", class_weights)\n",
    "\n",
    "    if (epoch + 1) % 3 == 0 and next_layer_to_unfreeze >= 0:\n",
    "            print(f\"Unfreezing BERT layer {next_layer_to_unfreeze}\")\n",
    "            unfreeze_bert_layer(model.bert_model, next_layer_to_unfreeze)\n",
    "            \n",
    "            next_layer_to_unfreeze -= 1\n",
    "\n",
    "\n",
    "# Load Best Model\n",
    "print(\"Loading best model for final evaluation.\")\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "\n",
    "##############################################################################\n",
    "# Test Evaluation\n",
    "##############################################################################\n",
    "print(\"\\nStarting Test Evaluation...\")\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "all_test_predictions, all_test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "    for batch in test_progress_bar:\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            pixel_values=pixel_values,\n",
    "            bert_input_ids=input_ids,\n",
    "            bert_attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs[\"logits\"]\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        all_test_predictions.extend(predictions.cpu().numpy())\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = accuracy_score(all_test_labels, all_test_predictions)\n",
    "test_uar = recall_score(all_test_labels, all_test_predictions, average=\"macro\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_predictions, average=\"macro\")\n",
    "\n",
    "metrics_str = (\n",
    "    f\"Test Loss: {avg_test_loss:.4f}, \"\n",
    "    f\"Accuracy: {test_accuracy:.4f}, \"\n",
    "    f\"UAR: {test_uar:.4f}, \"\n",
    "    f\"F1: {test_f1:.4f}\"\n",
    ")\n",
    "print(metrics_str)\n",
    "\n",
    "\n",
    "# Step 1: Define your label mapping\n",
    "# label_mapping = {'D': 0, 'H': 1, 'A': 2, 'O': 3, 'N': 4, 'C': 5, 'F': 6, 'S': 7}\n",
    "inv_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "\n",
    "# Suppose these are your test labels and predictions (as numeric):\n",
    "# all_test_labels = [...]\n",
    "# all_test_predictions = [...]\n",
    "\n",
    "\n",
    "# Step 2: Specify an order for the numeric labels\n",
    "\n",
    "# Suppose these are your test labels and predictions (as numeric):\n",
    "# all_test_labels = [...]\n",
    "# all_test_predictions = [...]\n",
    "\n",
    "# # Step 3: Generate the confusion matrix\n",
    "# cm = confusion_matrix(\n",
    "#     y_true=all_test_labels, \n",
    "#     y_pred=all_test_predictions, \n",
    "#     # labels=ordered_labels_numeric\n",
    "# )\n",
    "plot_and_save_confusion_matrix(all_test_labels, all_test_predictions, ordered_labels_str, output_dir, epoch=None)\n",
    "# # Step 4: Plot the confusion matrix with custom axis labels\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(\n",
    "#     cm,\n",
    "#     annot=True,\n",
    "#     fmt=\"d\",\n",
    "#     cmap=\"Blues\",\n",
    "#     xticklabels=ordered_labels_str,\n",
    "#     yticklabels=ordered_labels_str\n",
    "# )\n",
    "# plt.xlabel(\"Predicted Labels\")\n",
    "# plt.ylabel(\"True Labels\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# # Save and close\n",
    "# save_path = os.path.join(output_dir, \"confusion_matrix.png\")\n",
    "# plt.savefig(save_path, bbox_inches=\"tight\", dpi=300)\n",
    "# plt.close()\n",
    "# print(f\"Confusion matrix saved to: {save_path}\")\n",
    "\n",
    "# # Save Metadata\n",
    "# save_training_metadata(\n",
    "#     output_dir=output_dir,\n",
    "#     pathstr=pretrain_model,\n",
    "#     dataset_name=dataset_name,\n",
    "#     model_type=\"CombinedModelsDDCA\",\n",
    "#     super_loss_params=\"N/A\",\n",
    "#     speaker_disentanglement=True,\n",
    "#     entropy=False,\n",
    "#     column=\"label\",\n",
    "#     metrics=metrics_str,\n",
    "#     weight_decay=training_args.weight_decay,\n",
    "#     results=metrics_str\n",
    "# )\n",
    "\n",
    "# Overall Metrics (if needed across multiple runs):\n",
    "# For a single run, these will just match the test metrics.\n",
    "overall_accuracy = test_accuracy\n",
    "overall_UAR = test_uar\n",
    "overall_F1 = test_f1\n",
    "full_accuracy = test_accuracy\n",
    "\n",
    "# Save final metrics\n",
    "output_file = os.path.join(output_dir, \"metrics.txt\")\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(f\"Overall F1 Score: {overall_F1:.4f}\\n\")\n",
    "    f.write(f\"Overall Accuracy: {overall_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Full Accuracy: {full_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Overall UAR: {overall_UAR:.4f}\\n\")\n",
    "    f.write(f\" Class Mapping :{label_mapping}\\n\")\n",
    "    f.write(f\" Best Epoch :{best_epoch}\\n\")\n",
    "\n",
    "print(f\"Metrics saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d503d975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rml/Documents/pythontest/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "/home/rml/Documents/pythontest/.venv/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in dataset: {1, 3, 6, 10, 11, 12, 14, 15, 21, 24, 25, 26, 31, 37, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 61, 62, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 135, 136, 137, 139, 140, 142, 144, 145, 146, 147, 149, 154, 156, 157, 158, 161, 163, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 969, 970, 971, 972, 973, 974, 975, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1119, 1120, 1124, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1160, 1161, 1162, 1163, 1164, 1165, 1167, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1190, 1191, 1192, 1193, 1194, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1328, 1329, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1360, 1361, 1364, 1365, 1371, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1564, 1565, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1610, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1640, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1654, 1655, 1656, 1657, 1658, 1659, 1661, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1695, 1696, 1697, 1698, 1699, 1705, 1706, 1707, 1708, 1709, 1710, 1712, 1716, 1767, 1769, 1772, 1773, 1775, 1781, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1792, 1793, 1794, 1798, 1800, 1801, 1804, 1806, 1808, 1810, 1812, 1813, 1814, 1816, 1817, 1818, 1819, 1821, 1824, 1825, 1827, 1828, 1830, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1840, 1841, 1844, 1845, 1847, 1849, 1850, 1851, 1852, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1864, 1866, 1871, 1873, 1875, 1876, 1877, 1880, 1881, 1883, 1884, 1889, 1890, 1891, 1892, 1894, 1895, 1897, 1898, 1899, 1900, 1901, 1902, 1905, 1906, 1907, 1909, 1910, 1911, 1912, 1913, 1915, 1916, 1917, 1918, 1920, 1921, 1923, 1924, 1926, 1927, 1928, 1930, 1931, 1932, 1937, 1938, 1944, 1945, 1946, 1947, 1948, 1950, 1951, 1952, 1954, 1955, 1956, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1980, 1981, 1983, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1996, 1998, 1999, 2000, 2001, 2002, 2003, 2005, 2006, 2008, 2010, 2011, 2013, 2014, 2016, 2017, 2018, 2019, 2021, 2022, 2024, 2025, 2027, 2028, 2029, 2031, 2035, 2037, 2039, 2044, 2045, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2056, 2058, 2059, 2060, 2061, 2063, 2064, 2065, 2066, 2069, 2070, 2071, 2073, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2086, 2087, 2091, 2092, 2093, 2095, 2096, 2097, 2098, 2099, 2101, 2102, 2103, 2104, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2124, 2125, 2127, 2129, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2142, 2143, 2144, 2146, 2151, 2153, 2155, 2158, 2159, 2160, 2161, 2163, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2178, 2179, 2180, 2181, 2182, 2184, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2197, 2198, 2199, 2200, 2201, 2204, 2207, 2209, 2211, 2213, 2214, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2228, 2230, 2231, 2232, 2233, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2256, 2257, 2259, 2260, 2261, 2262, 2263, 2264, 2266, 2268, 2269, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2548, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2557, 2561, 2563, 2564, 2565, 2566, 2567, 2569, 2570, 2571, 2572, 2573, 2575, 2576, 2577, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2588, 2589, 2590, 2592, 2594, 2595, 2597, 2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2607, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2636, 2637, 2638, 2639, 2641, 2642, 2644, 2645, 2646, 2647, 2648, 2649, 2650, 2651, 2652, 2654, 2655, 2656, 2657, 2658, 2661, 2662, 2663, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2674, 2675, 2676, 2677, 2678, 2679, 2680, 2681, 2683, 2684, 2685, 2686, 2687, 2688, 2689, 2690, 2691, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2701, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2710, 2711, 2712, 2713, 2714, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723, 2724, 2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735, 2736, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2745, 2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767, 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2780, 2781, 2782, 2783, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2843, 2844, 2845, 2846, 2847, 2848, 2849, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 2859, 2861, 2862, 2863, 2864, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2872, 2873, 2874, 2875, 2877, 2878, 2879, 2880, 2881, 2882, 2884, 2885, 2886, 2887, 2889, 2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905, 2906, 2907, 2909, 2910, 2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919, 2920, 2921, 2922, 2923, 2924, 2925, 2926, 2927, 2928, 2929, 2930, 2931, 2932, 2933, 2934, 2935, 2936, 2937, 2938, 2939, 2940, 2941, 2942, 2943, 2944, 2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2966, 2967, 2968, 2969, 2970, 2971, 2972, 2973, 2976, 2978, 2979, 2980, 2981, 2982, 2983, 2984, 2985, 2986, 2987, 2988, 2989, 2990, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3109, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144, 3145, 3146, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3159, 3160, 3161, 3162, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3173, 3174, 3175, 3177, 3178, 3179, 3180, 3181, 3182, 3184, 3185, 3186, 3187, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3217, 3218, 3219, 3220, 3221, 3222, 3223, 3224, 3225, 3226, 3227, 3228, 3229, 3230, 3231, 3232, 3233, 3234, 3235, 3236, 3237, 3238, 3239, 3240, 3241, 3242, 3243, 3244, 3245, 3246, 3247, 3248, 3249, 3250, 3251, 3252, 3253, 3254, 3255, 3256, 3257, 3258, 3259, 3260, 3261, 3262, 3263, 3264, 3265, 3266, 3267, 3268, 3269, 3270, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3308, 3309, 3310, 3311, 3312, 3313, 3314, 3315, 3316, 3317, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3325, 3326, 3327, 3328, 3330, 3331, 3332}\n",
      "Total unique speakers: 2826\n",
      "Train dataset size: 79980\n",
      "Validation dataset size: 16138\n",
      "Test dataset size: 20015\n",
      "Unique speakers in train: 2588\n",
      "Unique speakers in val: 1889\n",
      "Unique speakers in test: 2826\n",
      "Speakers appearing in all splits: 1889 of 2826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DinatForImageClassification were not initialized from the model checkpoint at shi-labs/dinat-mini-in1k-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([2826, 512]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2826]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/rml/Documents/pythontest/.venv/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Training Loss: 8.0342\n",
      "Validation Loss: 7.6700, Accuracy: 0.0396, UAR: 0.0005, F1: 0.0000, UAR STD: 0.02300218208830115 \n",
      "Per-class Recall: [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Hugging Face Transformers\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    DinatForImageClassification,\n",
    "    TrainingArguments,\n",
    "    get_scheduler,\n",
    "    BertModel,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "# Hugging Face Datasets\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "# Data processing and metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.auto import tqdm\n",
    "best_epoch = 0\n",
    "# Custom functions (from your own module)\n",
    "from functionsV3 import *\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Set base_column to SpkrID explicitly\n",
    "base_column = \"SpkrID\"\n",
    "\n",
    "# Directories and Model Config\n",
    "base_dir = \"/home/rml/Documents/pythontest/Trained_Models/curr/spkr\"\n",
    "output_dir = create_unique_output_dir(base_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "DATASET_PATH = \"../data\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = \"shi-labs/dinat-mini-in1k-224\"  # For processor loading if needed\n",
    "checkpoint_path = None  # Remove previous checkpoint path\n",
    "pretrain_model = model_path\n",
    "bert_model_name = \"bert-base-uncased\"\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "# Load Dataset\n",
    "dataset_name = \"cairocode/MSPP_MEL_6\"\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "unique_labels = set(dataset['train'][base_column])\n",
    "print(\"Unique labels in dataset:\", unique_labels)\n",
    "\n",
    "label_mapping = {label: i for i, label in enumerate(sorted(unique_labels))}\n",
    "# Reverse the mapping for efficient lookup\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "num_labels = len(label_mapping)\n",
    "\n",
    "# Define a filtering function\n",
    "def is_mappable(example):\n",
    "    return example[base_column] in label_mapping\n",
    "\n",
    "column = \"label\"\n",
    "\n",
    "# Filter out rows with unmappable values\n",
    "filtered_dataset = dataset.filter(is_mappable)\n",
    "\n",
    "# Map the filtered dataset to add the new column\n",
    "filtered_dataset = filtered_dataset.map(lambda x: {\"label\": label_mapping[x[base_column]]})\n",
    "\n",
    "# Define a filtering function for transcripts\n",
    "def is_valid_transcript(example):\n",
    "    return isinstance(example['transcript'], str)\n",
    "\n",
    "# Filter out non-string transcripts\n",
    "filtered_dataset = filtered_dataset.filter(is_valid_transcript)\n",
    "\n",
    "inv_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Specify an order for displaying labels\n",
    "ordered_labels_str = [inv_label_mapping[i] for i in range(num_labels)]\n",
    "\n",
    "# MODIFIED: New data splitting approach to ensure each speaker appears in all sets\n",
    "# Get all unique speakers\n",
    "all_speakers = list(set(filtered_dataset['train'][base_column]))\n",
    "print(f\"Total unique speakers: {len(all_speakers)}\")\n",
    "\n",
    "# Create a dictionary to track examples per speaker\n",
    "examples_by_speaker = defaultdict(list)\n",
    "for i, example in enumerate(filtered_dataset['train']):\n",
    "    examples_by_speaker[example[base_column]].append(i)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Initialize empty lists for train, val, test indices\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "test_indices = []\n",
    "\n",
    "# For each speaker, split their examples into train (70%), val (15%), test (15%)\n",
    "for speaker, indices in examples_by_speaker.items():\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    # Calculate split points\n",
    "    n_total = len(indices)\n",
    "    n_train = int(0.7 * n_total)\n",
    "    n_val = int(0.15 * n_total)\n",
    "    \n",
    "    # Split indices\n",
    "    train_indices.extend(indices[:n_train])\n",
    "    val_indices.extend(indices[n_train:n_train + n_val])\n",
    "    test_indices.extend(indices[n_train + n_val:])\n",
    "\n",
    "# Create the datasets using the indices\n",
    "train_dataset = filtered_dataset['train'].select(train_indices)\n",
    "val_dataset = filtered_dataset['train'].select(val_indices)\n",
    "test_dataset = filtered_dataset['train'].select(test_indices)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(\"Train dataset size:\", len(train_dataset))\n",
    "print(\"Validation dataset size:\", len(val_dataset))\n",
    "print(\"Test dataset size:\", len(test_dataset))\n",
    "\n",
    "# Verify that each speaker appears in all splits\n",
    "train_speakers = set(train_dataset[base_column])\n",
    "val_speakers = set(val_dataset[base_column])\n",
    "test_speakers = set(test_dataset[base_column])\n",
    "\n",
    "print(f\"Unique speakers in train: {len(train_speakers)}\")\n",
    "print(f\"Unique speakers in val: {len(val_speakers)}\")\n",
    "print(f\"Unique speakers in test: {len(test_speakers)}\")\n",
    "\n",
    "# Check the intersection of speakers across splits\n",
    "common_speakers = train_speakers.intersection(val_speakers).intersection(test_speakers)\n",
    "print(f\"Speakers appearing in all splits: {len(common_speakers)} of {len(all_speakers)}\")\n",
    "\n",
    "# Apply transforms\n",
    "train_dataset.set_transform(train_transforms)\n",
    "val_dataset.set_transform(val_transforms)\n",
    "test_dataset.set_transform(val_transforms)\n",
    "\n",
    "# Create data loaders (no custom sampler needed)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda examples: collate_fn_reg(examples, column=column),\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=lambda examples: collate_fn_reg(examples, column=column),\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=lambda examples: collate_fn_reg(examples, column=column),\n",
    ")\n",
    "\n",
    "# Load Models\n",
    "image_model = DinatForImageClassification.from_pretrained(\n",
    "    pretrain_model,\n",
    "    num_labels=num_labels,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    problem_type=\"single_label_classification\",\n",
    ").to(device)\n",
    "\n",
    "processor = DinatForImageClassification.from_pretrained(model_path).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = BertModel.from_pretrained(bert_model_name).to(device)\n",
    "\n",
    "# Initialize the Combined Model\n",
    "unfozen_layers = [10, 11]\n",
    "next_layer_to_unfreeze = unfozen_layers[0] - 1\n",
    "\n",
    "model = CombinedModelsBi(\n",
    "    image_model=image_model,\n",
    "    bert_model=bert_model,\n",
    "    image_feature_dim=512,\n",
    "    bert_embedding_dim=768,\n",
    "    combined_dim=512,\n",
    "    num_labels=num_labels,\n",
    "    unfrozen_layers=unfozen_layers\n",
    ").to(device)\n",
    "\n",
    "# Configure training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./logs\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "logging.getLogger().addHandler(logging.NullHandler())\n",
    "logging.getLogger(\"natten.functional\").setLevel(logging.ERROR)\n",
    "\n",
    "# Optimizer & Scheduler\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=training_args.learning_rate,\n",
    "    weight_decay=training_args.weight_decay\n",
    ")\n",
    "\n",
    "num_training_steps = len(train_loader) * training_args.num_train_epochs\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=training_args.warmup_steps,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "# Use standard cross entropy with contrastive loss, but don't apply balanced weighting\n",
    "cecc_loss = CrossEntropyWithContrastiveCenterLoss(\n",
    "    num_classes=num_labels,\n",
    "    feature_dim=512,\n",
    "    alpha=1.0,\n",
    "    beta=0.01\n",
    ")\n",
    "\n",
    "# Training Variables\n",
    "num_epochs = training_args.num_train_epochs\n",
    "patience = 12\n",
    "best_val_accuracy = 0\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses, val_losses, epochs_list = [], [], []\n",
    "\n",
    "best_model_path = os.path.join(output_dir, \"best_model.pt\")\n",
    "\n",
    "##############################################################################\n",
    "# Training Loop\n",
    "##############################################################################\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            pixel_values=pixel_values,\n",
    "            bert_input_ids=input_ids,\n",
    "            bert_attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs[\"logits\"]\n",
    "        features = outputs[\"combined_features\"]\n",
    "\n",
    "        # Use simple cross entropy with contrastive loss\n",
    "        loss = cecc_loss(logits, features, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        progress_bar.set_postfix({\"Loss\": loss.item()})\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {avg_train_loss:.4f}\")\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_predictions, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                pixel_values=pixel_values,\n",
    "                bert_input_ids=input_ids,\n",
    "                bert_attention_mask=attention_mask\n",
    "            )\n",
    "            logits = outputs[\"logits\"]\n",
    "            features = outputs[\"combined_features\"]\n",
    "\n",
    "            loss = cecc_loss(logits, features, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    uar = recall_score(all_labels, all_predictions, average=\"macro\")\n",
    "    f1 = f1_score(all_labels, all_predictions, average=\"macro\")\n",
    "    per_class_recall = recall_score(all_labels, all_predictions, average=None)\n",
    "    uar_std = np.std(per_class_recall)\n",
    "\n",
    "    # Use simple UAR as comparison metric instead of penalizing by std\n",
    "    comparison_metric = uar\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    epochs_list.append(epoch + 1)\n",
    "\n",
    "    print(\n",
    "        f\"Validation Loss: {avg_val_loss:.4f}, \"\n",
    "        f\"Accuracy: {accuracy:.4f}, UAR: {uar:.4f}, F1: {f1:.4f}, UAR STD: {uar_std} \"\n",
    "        f\"\\nPer-class Recall: {per_class_recall}\"\n",
    "    )\n",
    "    \n",
    "    # Save confusion matrix\n",
    "    plot_and_save_confusion_matrix(all_labels, all_predictions, ordered_labels_str, output_dir, epoch=epoch)\n",
    "\n",
    "    # Early Stopping based on UAR\n",
    "    if comparison_metric > best_val_accuracy:\n",
    "        best_val_accuracy = comparison_metric\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        best_epoch = epoch\n",
    "        print(\"Validation UAR improved. Best model saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    # Gradually unfreeze BERT layers\n",
    "    if (epoch + 1) % 3 == 0 and next_layer_to_unfreeze >= 0:\n",
    "        print(f\"Unfreezing BERT layer {next_layer_to_unfreeze}\")\n",
    "        unfreeze_bert_layer(model.bert_model, next_layer_to_unfreeze)\n",
    "        next_layer_to_unfreeze -= 1\n",
    "\n",
    "# Load Best Model\n",
    "print(\"Loading best model for final evaluation.\")\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "\n",
    "##############################################################################\n",
    "# Test Evaluation\n",
    "##############################################################################\n",
    "print(\"\\nStarting Test Evaluation...\")\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "all_test_predictions, all_test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "    for batch in test_progress_bar:\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            pixel_values=pixel_values,\n",
    "            bert_input_ids=input_ids,\n",
    "            bert_attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs[\"logits\"]\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        all_test_predictions.extend(predictions.cpu().numpy())\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = accuracy_score(all_test_labels, all_test_predictions)\n",
    "test_uar = recall_score(all_test_labels, all_test_predictions, average=\"macro\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_predictions, average=\"macro\")\n",
    "\n",
    "metrics_str = (\n",
    "    f\"Test Loss: {avg_test_loss:.4f}, \"\n",
    "    f\"Accuracy: {test_accuracy:.4f}, \"\n",
    "    f\"UAR: {test_uar:.4f}, \"\n",
    "    f\"F1: {test_f1:.4f}\"\n",
    ")\n",
    "print(metrics_str)\n",
    "\n",
    "# Generate final confusion matrix\n",
    "plot_and_save_confusion_matrix(all_test_labels, all_test_predictions, ordered_labels_str, output_dir, epoch=None)\n",
    "\n",
    "# Overall Metrics\n",
    "overall_accuracy = test_accuracy\n",
    "overall_UAR = test_uar\n",
    "overall_F1 = test_f1\n",
    "full_accuracy = test_accuracy\n",
    "\n",
    "# Save final metrics\n",
    "output_file = os.path.join(output_dir, \"metrics.txt\")\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(f\"Overall F1 Score: {overall_F1:.4f}\\n\")\n",
    "    f.write(f\"Overall Accuracy: {overall_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Full Accuracy: {full_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Overall UAR: {overall_UAR:.4f}\\n\")\n",
    "    f.write(f\"Class Mapping: {label_mapping}\\n\")\n",
    "    f.write(f\"Best Epoch: {best_epoch}\\n\")\n",
    "    f.write(f\"Training speakers: {len(train_speakers)}\\n\")\n",
    "    f.write(f\"Validation speakers: {len(val_speakers)}\\n\")\n",
    "    f.write(f\"Test speakers: {len(test_speakers)}\\n\")\n",
    "    f.write(f\"Speakers in all splits: {len(common_speakers)}\\n\")\n",
    "\n",
    "print(f\"Metrics saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91f124-a36d-4e6b-943d-6cbb1cf9438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone https://github.com/google/sentencepiece.git \n",
    "# cd sentencepiece\n",
    "#  mkdir build\n",
    "#  cd build\n",
    "#  cmake ..\n",
    "#  make -j $(nproc)\n",
    "#  sudo make install\n",
    "#  sudo ldconfig -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2f686e-5351-4f41-8da9-bc36b45bf4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Best Model\n",
    "print(\"Loading best model for final evaluation.\")\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "\n",
    "##############################################################################\n",
    "# Test Evaluation\n",
    "##############################################################################\n",
    "print(\"\\nStarting Test Evaluation...\")\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "all_test_predictions, all_test_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "    for batch in test_progress_bar:\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            pixel_values=pixel_values,\n",
    "            bert_input_ids=input_ids,\n",
    "            bert_attention_mask=attention_mask\n",
    "        )\n",
    "        logits = outputs[\"logits\"]\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        all_test_predictions.extend(predictions.cpu().numpy())\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = accuracy_score(all_test_labels, all_test_predictions)\n",
    "test_uar = recall_score(all_test_labels, all_test_predictions, average=\"macro\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_predictions, average=\"macro\")\n",
    "\n",
    "metrics_str = (\n",
    "    f\"Test Loss: {avg_test_loss:.4f}, \"\n",
    "    f\"Accuracy: {test_accuracy:.4f}, \"\n",
    "    f\"UAR: {test_uar:.4f}, \"\n",
    "    f\"F1: {test_f1:.4f}\"\n",
    ")\n",
    "print(metrics_str)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d5506-d658-418b-97df-f709bfb93df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save_confusion_matrix(all_test_labels, all_test_predictions, ordered_labels_str, output_dir, epoch=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fceca55-907b-401a-9f6d-19b48539fcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b212289-a38e-468d-886a-3f59048050e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Define your label mapping\n",
    "# label_mapping = {'D': 0, 'H': 1, 'A': 2, 'O': 3, 'N': 4, 'C': 5, 'F': 6, 'S': 7}\n",
    "inv_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "\n",
    "# Step 2: Specify an order for the numeric labels\n",
    "ordered_labels_numeric = [0, 1, 2, 3, 4, 5, 6, 7 ]#, 7]\n",
    "ordered_labels_str = [label_mapping[i] for i in ordered_labels_numeric]\n",
    "\n",
    "# all_test_labels = [...]\n",
    "# all_test_predictions = [...]\n",
    "\n",
    "# # Step 3: Generate the confusion matrix\n",
    "# cm = confusion_matrix(\n",
    "#     y_true=all_test_labels, \n",
    "#     y_pred=all_test_predictions, \n",
    "#     # labels=ordered_labels_numeric\n",
    "# )\n",
    "\n",
    "# # Step 4: Plot the confusion matrix with custom axis labels\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(\n",
    "#     cm,\n",
    "#     annot=True,\n",
    "#     fmt=\"d\",\n",
    "#     cmap=\"Blues\",\n",
    "#     xticklabels=ordered_labels_str,\n",
    "#     yticklabels=ordered_labels_str\n",
    "# )\n",
    "# plt.xlabel(\"Predicted Labels\")\n",
    "# plt.ylabel(\"True Labels\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# # Save and close\n",
    "# save_path = os.path.join(output_dir, \"confusion_matrix.png\")\n",
    "# plt.savefig(save_path, bbox_inches=\"tight\", dpi=300)\n",
    "# plt.close()\n",
    "# print(f\"Confusion matrix saved to: {save_path}\")\n",
    "\n",
    "# # # Save Metadata\n",
    "# # save_training_metadata(\n",
    "# #     output_dir=output_dir,\n",
    "# #     pathstr=pretrain_model,\n",
    "# #     dataset_name=dataset_name,\n",
    "# #     model_type=\"CombinedModelsDDCA\",\n",
    "# #     super_loss_params=\"N/A\",\n",
    "# #     speaker_disentanglement=True,\n",
    "# #     entropy=False,\n",
    "# #     column=\"label\",\n",
    "# #     metrics=metrics_str,\n",
    "# #     weight_decay=training_args.weight_decay,\n",
    "# #     results=metrics_str\n",
    "# # )\n",
    "\n",
    "# Overall Metrics (if needed across multiple runs):\n",
    "# For a single run, these will just match the test metrics.\n",
    "overall_accuracy = test_accuracy\n",
    "overall_UAR = test_uar\n",
    "overall_F1 = test_f1\n",
    "full_accuracy = test_accuracy\n",
    "\n",
    "# Save final metrics\n",
    "output_file = os.path.join(output_dir, \"metrics.txt\")\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(f\"Overall F1 Score: {overall_F1:.4f}\\n\")\n",
    "    f.write(f\"Overall Accuracy: {overall_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Full Accuracy: {full_accuracy:.4f}\\n\")\n",
    "    f.write(f\"Overall UAR: {overall_UAR:.4f}\\n\")\n",
    "    f.write(f\"Class Mapping :{label_mapping}\\n\")\n",
    "    f.write(f\" Best Epoch :{best_epoch}\\n\")\n",
    "    \n",
    "    f.write(f\"--------------PARAMETERS --------------\\n\")\n",
    "    f.write(f\"Pretrain Model :{pretrain_model}\\n\")\n",
    "    f.write(f\"Dataset Name: {dataset_name}\\n\")\n",
    "    f.write(f\"Class Weights :{class_weights}\\n\")\n",
    "    f.write(f\"Weight Decay: {training_args.weight_decay}\\n\")\n",
    "    f.write(f\"Model Type  CombinedModelsBi \\n\")\n",
    "    \n",
    "\n",
    "print(f\"Metrics saved to {output_file}\")\n",
    "\n",
    "inv_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e7b9c-058c-4577-9644-8e9d7681d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from datasets import DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "from functions_old import *\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    ViTForImageClassification,\n",
    "    BertModel,\n",
    "    AutoTokenizer,\n",
    "    get_scheduler,\n",
    "    DinatForImageClassification,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "# Load Best Model\n",
    "print(\"Loading best model for final evaluation.\")\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def collate_fn_test(examples):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle batching of image data and BERT inputs.\n",
    "    \"\"\"\n",
    "    # print(examples)\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"]\n",
    "                               for example in examples]).to(device)\n",
    "    input_ids = torch.stack([example[\"input_ids\"]\n",
    "                            for example in examples]).to(device)\n",
    "    attention_mask = torch.stack(\n",
    "        [example[\"attention_mask\"] for example in examples]).to(device)\n",
    "    files = [example[\"file\"] for example in examples]\n",
    "\n",
    "    bert_embeddings = torch.stack(\n",
    "        [example[\"bert_embeddings\"] for example in examples]).to(device)\n",
    "\n",
    "    return {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"files\": files,\n",
    "        \"bert_embeddings\": bert_embeddings\n",
    "    }\n",
    "\n",
    "# checkpoint_path = \"./DinatCurriculum/Regression/Valence/20250116_19/best_model.pt\"\n",
    "# output_dir = \"./DinatCurriculum/Regression/Valence/20250116_19/\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "dataset_name = 'cairocode/MSPP_TEST_MEL_6'\n",
    "# test_dataset = \n",
    "test_dataset = load_dataset(dataset_name)['test']\n",
    "\n",
    "test_dataset.set_transform(train_transforms)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=50,\n",
    "    collate_fn=collate_fn_test,\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nStarting Test Evaluation...\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "all_test_predictions = []\n",
    "all_test_labels = []\n",
    "all_filenames = []  # To store filenames\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "    for batch in test_progress_bar:\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        # labels = batch[\"labels\"].float().to(device)\n",
    "\n",
    "        # Extract filenames from the batch (assuming \"filename\" is part of batch)\n",
    "        filenames = batch[\"files\"]  # Adjust key as necessary\n",
    "        all_filenames.extend(filenames)\n",
    "\n",
    "        outputs_dict = model(\n",
    "            pixel_values=pixel_values,\n",
    "            bert_input_ids=input_ids,\n",
    "            bert_attention_mask=attention_mask\n",
    "        )\n",
    "        predictions = outputs_dict[\"logits\"].argmax(dim=-1)  # Convert logits to class indices\n",
    "\n",
    "        # loss = criterion(predictions, labels)\n",
    "        # test_loss += loss.item()\n",
    "\n",
    "        all_test_predictions.extend(predictions.cpu().numpy())\n",
    "        # all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "# Correct the mapping logic\n",
    "# Ensure each prediction is converted to an integer before mapping\n",
    "mapped_labels = [label_mapping[int(pred)] for pred in all_test_predictions]\n",
    "\n",
    "output_csv_path = os.path.join(output_dir, \"test_predictions.csv\")\n",
    "with open(output_csv_path, mode=\"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"Filename\", \"Category\"])\n",
    "    for filename, prediction in zip(all_filenames, mapped_labels):\n",
    "        writer.writerow([filename, prediction])\n",
    "\n",
    "print(f\"Predictions saved to {output_csv_path}\")\n",
    "\n",
    "# print(dataset_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
