{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rml/Documents/pythontest/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Some weights of DinatForImageClassification were not initialized from the model checkpoint at shi-labs/dinat-mini-in1k-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([1, 512]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_780874/3164830471.py:216: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n",
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Training Loss: 0.5734\n",
      "Validation Loss: 0.5172 Metrics: {'CCC': np.float32(0.6010388), 'R^2': 0.18839091062545776}\n",
      "Validation loss improved. Saving best model and resetting patience counter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Training Loss: 0.5242\n",
      "Validation Loss: 0.5124 Metrics: {'CCC': np.float32(0.6013467), 'R^2': 0.22934812307357788}\n",
      "Validation loss improved. Saving best model and resetting patience counter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Training Loss: 0.5013\n",
      "Validation Loss: 0.5086 Metrics: {'CCC': np.float32(0.6040397), 'R^2': 0.24072754383087158}\n",
      "Validation loss improved. Saving best model and resetting patience counter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Training Loss: 0.4806\n",
      "Validation Loss: 0.5106 Metrics: {'CCC': np.float32(0.6004127), 'R^2': 0.2573062777519226}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Training Loss: 0.4602\n",
      "Validation Loss: 0.5163 Metrics: {'CCC': np.float32(0.59312654), 'R^2': 0.27549856901168823}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Training Loss: 0.4405\n",
      "Validation Loss: 0.5264 Metrics: {'CCC': np.float32(0.57807785), 'R^2': 0.29678189754486084}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Training Loss: 0.4246\n",
      "Validation Loss: 0.5311 Metrics: {'CCC': np.float32(0.566581), 'R^2': 0.31355226039886475}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Training Loss: 0.4120\n",
      "Validation Loss: 0.5365 Metrics: {'CCC': np.float32(0.5544069), 'R^2': 0.32086455821990967}\n",
      "Early stopping triggered. Stopping training.\n",
      "Loading best model for final evaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_780874/3164830471.py:415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Test Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.5800 Metrics: {'CCC': np.float32(0.562535), 'R^2': 0.19434547424316406}\n",
      "Training metadata saved successfully at: /home/rml/Documents/pythontest/Trained_Models/curr_V2/EmoDom/20250310_1/training_metadata.txt\n",
      "Metrics saved to /home/rml/Documents/pythontest/Trained_Models/curr_V2/EmoDom/20250310_1/metrics.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/wasef-c/EmoSpeech.git\n",
    "# !pip install transformers[torch] torch datasets seaborn matplotlib scikit-learn\n",
    "# !pip install --upgrade Pillow\n",
    "# TRY WEIGHING IMAGE MDEL HIGEHR\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    ViTForImageClassification,\n",
    "    BertModel,\n",
    "    AutoTokenizer,\n",
    "    get_scheduler,\n",
    "    DinatForImageClassification,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "import os\n",
    "# Custom imports from your \"functions_older.py\" (adjust as needed)\n",
    "from functions_old import *\n",
    "def compute_regression_metrics(predictions, labels):\n",
    "    \"\"\"\n",
    "    For regression: compute CCC and R^2.\n",
    "\n",
    "    eval_pred: (predictions, labels)\n",
    "       predictions: np.array of shape (N,) or (N,1)\n",
    "       labels:      np.array of shape (N,) or (N,1)\n",
    "    \"\"\"\n",
    "    # predictions, labels = eval_pred\n",
    "\n",
    "    # Make sure arrays are 1D if your model outputs (N,1)\n",
    "    predictions = np.squeeze(predictions)\n",
    "    labels = np.squeeze(labels)\n",
    "\n",
    "    ccc = concordance_correlation_coefficient(predictions, labels)\n",
    "    r2 = r2_score(labels, predictions)\n",
    "\n",
    "    return {\n",
    "        \"CCC\": ccc,\n",
    "        \"R^2\": r2\n",
    "    }\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "logging.getLogger().addHandler(logging.NullHandler())\n",
    "logging.getLogger(\"natten.functional\").setLevel(logging.ERROR)\n",
    "\n",
    "def collate_fn_reg(examples, column):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle batching of image data and BERT inputs.\n",
    "    \"\"\"\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples]).to(device)\n",
    "    input_ids = torch.stack([example[\"input_ids\"] for example in examples]).to(device)\n",
    "    attention_mask = torch.stack([example[\"attention_mask\"] for example in examples]).to(device)\n",
    "    labels = torch.tensor([example[column] for example in examples]).to(device)\n",
    "    bert_embeddings = torch.stack([example[\"bert_embeddings\"] for example in examples]).to(device)\n",
    "\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"pixel_values\": pixel_values,\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "        \"bert_embeddings\":bert_embeddings\n",
    "    }\n",
    "    \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "logging.getLogger().addHandler(logging.NullHandler())\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Configuration and Paths\n",
    "# ----------------------------------------------------------------------\n",
    "# r\"C:\\Users\\Paolo\\Documents\\carol_emo_rec\\MLLM\\Currciulum_Models\\Speaker\\20250107_6\\best_model.pt\"\n",
    "column = \"EmoDom\" #\"EmoVal\" ## or \"arousal\", \"score\", etc.\"EmoVal\" # \n",
    "\n",
    "# checkpoint_path = \"./DinatCurriculum/Regression/Activation/EmoAct/20250117_1/best_model.pt\"  #\"./DinatCurriculum/Regression/Valence/20250114_10/best_model.pt\"# None #\"./Curriculum/Regression/Valence/20250110_3/best_model.pt\" #\"./Curriculum/Regression/Activation/20250109_6/best_model.pt\"\n",
    "checkpoint_path = \"/home/rml/Documents/pythontest/Trained_Models/curr_V2/EmoAct/20250307_1/best_model.pt\" #None #\"/home/rml/Documents/pythontest/Trained_Models/curr/EmoAct/20250305_1/best_model.pt\"\n",
    "base_dir = os.path.join(\"/home/rml/Documents/pythontest/Trained_Models/curr_V2\", column)\n",
    "output_dir = create_unique_output_dir(base_dir)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 20\n",
    "WEIGHT_DECAY = 0.01\n",
    "PATIENCE = 5\n",
    "\n",
    "# Pre-trained model names (ViT + BERT)\n",
    "image_model_name = \"shi-labs/dinat-mini-in1k-224\"\n",
    "bert_model_name = \"bert-base-uncased\"\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Load Dataset\n",
    "# ----------------------------------------------------------------------\n",
    "dataset_name = 'cairocode/MSPP_MEL_6'\n",
    "dataset_name = 'cairocode/MSPP_SPLIT_MEL2'\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "\n",
    "# Define a filtering function\n",
    "def is_valid_transcript(example):\n",
    "    return isinstance(example['transcript'], str)\n",
    "\n",
    "# Filter out non-string transcripts in each split\n",
    "filtered_dataset = dataset.filter(is_valid_transcript)\n",
    "\n",
    "# seed = 42\n",
    "# random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# unique_speakers = set(filtered_dataset['train']['SpkrID'])\n",
    "# shuffled_speakers = list(unique_speakers)\n",
    "# random.shuffle(shuffled_speakers)\n",
    "\n",
    "# # Split speakers into 80% (train+val) and 20% (test)\n",
    "# split_idx = int(len(shuffled_speakers) * 0.8)\n",
    "# train_val_speakers = shuffled_speakers[:split_idx]\n",
    "# test_speakers = shuffled_speakers[split_idx:]\n",
    "\n",
    "# # Split the train_val set into 85% train and 15% validation\n",
    "# train_val_split_idx = int(len(train_val_speakers) * 0.85)\n",
    "# train_speakers = train_val_speakers[:train_val_split_idx]\n",
    "# val_speakers = train_val_speakers[train_val_split_idx:]\n",
    "\n",
    "# # Filter the dataset based on speaker IDs\n",
    "# train_dataset = filtered_dataset['train'].filter(lambda example: example['SpkrID'] in train_speakers)\n",
    "# val_dataset = filtered_dataset['train'].filter(lambda example: example['SpkrID'] in val_speakers)\n",
    "# test_dataset = filtered_dataset['train'].filter(lambda example: example['SpkrID'] in test_speakers)\n",
    "train_dataset = filtered_dataset['train']\n",
    "val_dataset = filtered_dataset['validation']\n",
    "test_dataset = filtered_dataset['test']\n",
    "\n",
    "\n",
    "# def rename_to_label(example):\n",
    "# #     # Convert to float if necessary\n",
    "#      return {\"r\": float(example[column])}\n",
    "\n",
    "\n",
    "# # 2) Map the transformation\n",
    "# dataset = dataset.map(rename_to_label)\n",
    "# train_dataset = dataset['train']\n",
    "# val_dataset = dataset['validation']\n",
    "# test_dataset = dataset['test']\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Set Transforms and Prepare Dataloaders\n",
    "# ----------------------------------------------------------------------\n",
    "train_dataset.set_transform(train_transforms)\n",
    "val_dataset.set_transform(val_transforms)\n",
    "test_dataset.set_transform(val_transforms)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    # sampler=CustomSampler(train_dataset),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=lambda examples: collate_fn_reg(examples, column=column),\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=lambda examples: collate_fn_reg(examples, column=column),\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=lambda examples: collate_fn_reg(examples, column=column),\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Initialize Image + Text Models\n",
    "# ----------------------------------------------------------------------\n",
    "    \n",
    "image_model = DinatForImageClassification.from_pretrained(\n",
    "    image_model_name,\n",
    "    num_labels=1,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    problem_type=\"regression\",\n",
    ").to(device)\n",
    "\n",
    "image_processor = DinatForImageClassification.from_pretrained(image_model_name).to(device)\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "base_bert_model = BertModel.from_pretrained(bert_model_name).to(device)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Initialize the Combined Regression Model\n",
    "# ----------------------------------------------------------------------\n",
    "model = CombinedModelsBi(\n",
    "    image_model=image_model,\n",
    "    bert_model=bert_model,\n",
    "    image_feature_dim=512,\n",
    "    bert_embedding_dim=768,\n",
    "    combined_dim=512,\n",
    "    num_labels=1,\n",
    "\n",
    ").to(device)\n",
    "\n",
    "\n",
    "if checkpoint_path != None:\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "    # # Option 1: Print each key on a separate line\n",
    "    # # for key in checkpoint.keys():\n",
    "    # #     print(key)\n",
    "\n",
    "    # Define the keywords to include and exclude\n",
    "    include_keyword = \"image_model\"\n",
    "    exclude_keys = {\n",
    "        \"image_model.classifier.weight\",\n",
    "        \"image_model.classifier.bias\"\n",
    "    }\n",
    "\n",
    "    # Use dictionary comprehension to filter the keys\n",
    "    filtered_checkpoint = {\n",
    "        key: value for key, value in checkpoint.items()\n",
    "        if include_keyword in key and key not in exclude_keys\n",
    "    }\n",
    "\n",
    "    # # Optional: Verify the filtered keys\n",
    "    # print(\"Filtered keys to be loaded:\")\n",
    "    # for key in filtered_checkpoint.keys():\n",
    "    #     print(f\"- {key}\")\n",
    "\n",
    "    # Load the filtered state dict\n",
    "    model.load_state_dict(filtered_checkpoint, strict=False)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Training Setup\n",
    "# ----------------------------------------------------------------------\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "num_training_steps = len(train_loader) * EPOCHS\n",
    "# lr_scheduler = get_scheduler(\n",
    "#     \"linear\",\n",
    "#     optimizer=optimizer,\n",
    "#     num_warmup_steps=0,\n",
    "#     num_training_steps=num_training_steps,\n",
    "# )\n",
    "lr_scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer,\n",
    "    T_0=10,  # Number of iterations for the first restart\n",
    "    T_mult=2,  # Multiplicative factor for subsequent restart periods\n",
    ")\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "\n",
    "class CCCLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CCCLoss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_true_mean = torch.mean(y_true)\n",
    "        y_pred_mean = torch.mean(y_pred)\n",
    "\n",
    "        y_true_var = torch.var(y_true, unbiased=False)\n",
    "        y_pred_var = torch.var(y_pred, unbiased=False)\n",
    "\n",
    "        covariance = torch.mean((y_true - y_true_mean)\n",
    "                                * (y_pred - y_pred_mean))\n",
    "\n",
    "        ccc = (2 * covariance) / (\n",
    "            y_true_var + y_pred_var + (y_true_mean - y_pred_mean) ** 2 + 1e-8\n",
    "        )  # Adding epsilon to avoid division by zero\n",
    "\n",
    "        loss = 1 - ccc\n",
    "        return loss\n",
    "\n",
    "\n",
    "criterion = CCCLoss()\n",
    "\n",
    "patience_counter = 0\n",
    "best_val_loss = 0 # float(\"inf\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "epochs_list = []\n",
    "best_model_path = os.path.join(output_dir, \"best_model.pt\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Training Loop\n",
    "# ----------------------------------------------------------------------\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    progress_bar = tqdm(\n",
    "        train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].float().to(device)  # Ensure labels are float for regression\n",
    "    \n",
    "        # Forward pass\n",
    "        outputs_dict = model(\n",
    "            pixel_values=pixel_values,\n",
    "            bert_input_ids=input_ids,\n",
    "            bert_attention_mask=attention_mask,\n",
    "            labels=labels  # Provide labels for DCCA loss\n",
    "        )\n",
    "    \n",
    "        # Predictions and primary regression loss\n",
    "        predictions = outputs_dict[\"logits\"].squeeze(-1)\n",
    "        regression_loss = criterion(predictions, labels)\n",
    "        # # Weighted total loss\n",
    "        # lambda_dcca = min(0.0, epoch / 50)  # Gradually increase\n",
    "        # lambda_recon = 0.0 #min(0.1, epoch / 500)\n",
    "\n",
    "        # total_loss = (\n",
    "        #     regression_loss\n",
    "        #     + lambda_dcca * dcca_loss\n",
    "        #     + lambda_recon * reconstruction_loss\n",
    "        # )\n",
    "        total_loss = regression_loss\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Accumulate and display losses in progress bar\n",
    "        train_loss += total_loss.item()\n",
    "        progress_bar.set_postfix({\n",
    "            \"total_loss\": total_loss.item(),\n",
    "        })\n",
    "    \n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Training Loss: {avg_train_loss:.4f}\")\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # Validation\n",
    "    # ------------------------------------------------------------------\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].float().to(device)\n",
    "\n",
    "            outputs_dict = model(\n",
    "                pixel_values=pixel_values,\n",
    "                bert_input_ids=input_ids,\n",
    "                bert_attention_mask=attention_mask\n",
    "            )\n",
    "            predictions = outputs_dict[\"logits\"].squeeze(-1)\n",
    "            loss = criterion(predictions, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    epochs_list.append(epoch + 1)\n",
    "    metrics = compute_regression_metrics(all_predictions, all_labels)\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f} Metrics: {metrics}\")\n",
    "\n",
    "    # Optional: compute regression metrics if you have them\n",
    "    # metrics_dict = compute_regression_metrics(all_predictions, all_labels)\n",
    "    # print(metrics_dict)\n",
    "\n",
    "    # Early stopping based on validation loss\n",
    "    # if avg_val_loss < best_val_loss:\n",
    "    #     best_val_loss = avg_val_loss\n",
    "    #     patience_counter = 0\n",
    "    #     torch.save(model.state_dict(), best_model_path)\n",
    "    #     print(\"Validation loss improved. Saving best model and resetting patience counter.\")\n",
    "    # else:\n",
    "    #     patience_counter += 1\n",
    "    #     if patience_counter >= PATIENCE:\n",
    "    #         print(\"Early stopping triggered. Stopping training.\")\n",
    "    #         break\n",
    "    if metrics['CCC'] > best_val_loss:\n",
    "        best_val_loss = metrics['CCC']\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(\"Validation loss improved. Saving best model and resetting patience counter.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Load Best Model for Final Evaluation\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"Loading best model for final evaluation.\")\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.to(device)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Test Evaluation\n",
    "# ----------------------------------------------------------------------\n",
    "print(\"\\nStarting Test Evaluation...\")\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "all_test_predictions = []\n",
    "all_test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "    for batch in test_progress_bar:\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].float().to(device)\n",
    "\n",
    "        outputs_dict = model(\n",
    "            pixel_values=pixel_values,\n",
    "            bert_input_ids=input_ids,\n",
    "            bert_attention_mask=attention_mask\n",
    "        )\n",
    "        predictions = outputs_dict[\"logits\"].squeeze(-1)\n",
    "\n",
    "        loss = criterion(predictions, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        all_test_predictions.extend(predictions.cpu().numpy())\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "metrics = compute_regression_metrics(all_test_predictions, all_test_labels)\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f} Metrics: {metrics}\")\n",
    "\n",
    "# If you have your own regression metrics function:\n",
    "# test_metrics = compute_regression_metrics(all_test_predictions, all_test_labels)\n",
    "# print(\"Test Metrics:\", test_metrics)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Save Final Results & Metadata\n",
    "# ----------------------------------------------------------------------\n",
    "final_metrics_str = f\"Test Loss: {avg_test_loss:.4f} Metrics: {metrics}\"\n",
    "save_training_metadata(\n",
    "    output_dir,\n",
    "    Pretrain_file = output_dir,\n",
    "    dataset_name=dataset_name,\n",
    "    model_type = \"DINAT DCCA\",\n",
    "    results = final_metrics_str,\n",
    "    column = column,\n",
    "    speaker_disentanglement = True,\n",
    "    metrics = final_metrics_str,\n",
    "    weight_decay = WEIGHT_DECAY,\n",
    "    class_weights=None,\n",
    "    speakers = None,\n",
    ")\n",
    "\n",
    "metrics_file = os.path.join(output_dir, \"metrics.txt\")\n",
    "with open(metrics_file, \"w\") as f:\n",
    "    f.write(final_metrics_str + \"\\n\")\n",
    "\n",
    "print(f\"Metrics saved to {metrics_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset_name = 'cairocode/MSPP_SPLIT_MEL2'\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to /home/rml/Documents/pythontest/Trained_Models/curr_V2/EmoDom/20250310_1/metrics.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "metrics_file = os.path.join(output_dir, \"metrics.txt\")\n",
    "with open(metrics_file, \"w\") as f:\n",
    "    f.write(final_metrics_str + \"\\n\")\n",
    "\n",
    "print(f\"Metrics saved to {metrics_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import DatasetDict\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import csv\n",
    "# from functions_older import *\n",
    "# import datasets\n",
    "# from datasets import load_dataset\n",
    "# import os\n",
    "# import logging\n",
    "# import warnings\n",
    "# import random\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# from transformers import (\n",
    "#     AutoImageProcessor,\n",
    "#     ViTForImageClassification,\n",
    "#     BertModel,\n",
    "#     AutoTokenizer,\n",
    "#     get_scheduler,\n",
    "# )\n",
    "# from datasets import load_dataset\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# def collate_fn_test(examples):\n",
    "#     \"\"\"\n",
    "#     Custom collate function to handle batching of image data and BERT inputs.\n",
    "#     \"\"\"\n",
    "#     # print(examples)\n",
    "#     pixel_values = torch.stack([example[\"pixel_values\"]\n",
    "#                                for example in examples]).to(device)\n",
    "#     input_ids = torch.stack([example[\"input_ids\"]\n",
    "#                             for example in examples]).to(device)\n",
    "#     attention_mask = torch.stack(\n",
    "#         [example[\"attention_mask\"] for example in examples]).to(device)\n",
    "#     files = [example[\"file\"] for example in examples]\n",
    "\n",
    "#     bert_embeddings = torch.stack(\n",
    "#         [example[\"bert_embeddings\"] for example in examples]).to(device)\n",
    "\n",
    "#     return {\n",
    "#         \"pixel_values\": pixel_values,\n",
    "#         \"input_ids\": input_ids,\n",
    "#         \"attention_mask\": attention_mask,\n",
    "#         \"files\": files,\n",
    "#         \"bert_embeddings\": bert_embeddings\n",
    "#     }\n",
    "\n",
    "# checkpoint_path = \"./DinatCurriculum/Regression/Valence/20250116_19/best_model.pt\"\n",
    "# output_dir = \"./DinatCurriculum/Regression/Valence/20250116_19/\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# dataset_name = 'cairocode/MSPP_TEST_SYL'\n",
    "# # test_dataset = \n",
    "# test_dataset = load_dataset(dataset_name)['test']\n",
    "\n",
    "# test_dataset.set_transform(test_transforms)\n",
    "\n",
    "# test_loader = DataLoader(\n",
    "#     test_dataset,\n",
    "#     batch_size=50,\n",
    "#     collate_fn=collate_fn_test,\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# image_model_name = \"google/vit-base-patch16-224\"\n",
    "# bert_model_name = \"bert-base-uncased\"\n",
    "\n",
    "# image_processor = AutoImageProcessor.from_pretrained(image_model_name)\n",
    "# image_model = ViTForImageClassification.from_pretrained(\n",
    "#     image_model_name,\n",
    "#     ignore_mismatched_sizes=True,\n",
    "#     num_labels=1,\n",
    "#     problem_type=\"regression\"\n",
    "# ).to(device)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "# base_bert_model = BertModel.from_pretrained(bert_model_name).to(device)\n",
    "\n",
    "# # ----------------------------------------------------------------------\n",
    "# # Initialize the Combined Regression Model\n",
    "# # ----------------------------------------------------------------------\n",
    "# model = CombinedModelsBi(\n",
    "#     image_model=image_model,\n",
    "#     bert_model=bert_model,\n",
    "#     image_feature_dim=768,   # Feature dim of ViT\n",
    "#     bert_embedding_dim=768,  # BERT embedding dim\n",
    "#     combined_dim=1024,       # Combined dimension\n",
    "#     num_labels=1\n",
    "# ).to(device)\n",
    "\n",
    "\n",
    "# if checkpoint_path != None:\n",
    "#     checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "\n",
    "\n",
    "# model.load_state_dict(torch.load(checkpoint_path))\n",
    "# model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # ----------------------------------------------------------------------\n",
    "# # Test Evaluation\n",
    "# # ----------------------------------------------------------------------\n",
    "# print(\"\\nStarting Test Evaluation...\")\n",
    "# model.eval()\n",
    "# test_loss = 0.0\n",
    "# all_test_predictions = []\n",
    "# all_test_labels = []\n",
    "# all_filenames = []  # To store filenames\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     test_progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n",
    "#     for batch in test_progress_bar:\n",
    "#         pixel_values = batch[\"pixel_values\"].to(device)\n",
    "#         input_ids = batch[\"input_ids\"].to(device)\n",
    "#         attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#         # labels = batch[\"labels\"].float().to(device)\n",
    "\n",
    "#         # Extract filenames from the batch (assuming \"filename\" is part of batch)\n",
    "#         filenames = batch[\"files\"]  # Adjust key as necessary\n",
    "#         all_filenames.extend(filenames)\n",
    "\n",
    "#         outputs_dict = model(\n",
    "#             pixel_values=pixel_values,\n",
    "#             bert_input_ids=input_ids,\n",
    "#             bert_attention_mask=attention_mask\n",
    "#         )\n",
    "#         predictions = outputs_dict[\"logits\"].squeeze(-1)\n",
    "\n",
    "#         # loss = criterion(predictions, labels)\n",
    "#         # test_loss += loss.item()\n",
    "\n",
    "#         all_test_predictions.extend(predictions.cpu().numpy())\n",
    "#         # all_test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "\n",
    "# output_csv_path = os.path.join(output_dir, \"test_predictions.csv\")\n",
    "# with open(output_csv_path, mode=\"w\", newline=\"\") as csv_file:\n",
    "#     writer = csv.writer(csv_file)\n",
    "#     writer.writerow([\"Filename\", \"Domination\"])\n",
    "#     for filename, prediction in zip(all_filenames, all_test_predictions):\n",
    "#         writer.writerow([filename, prediction])\n",
    "\n",
    "# print(f\"Predictions saved to {output_csv_path}\")\n",
    "\n",
    "# # print(dataset_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Step 1: Define a function to process a single CSV\n",
    "# # Step 1: Define a function to process a single CSV\n",
    "# def process_csv(file_path):\n",
    "#     # Load the CSV into a DataFrame\n",
    "#     df = pd.read_csv(file_path)\n",
    "\n",
    "#     # Group by 'Filename' and calculate the mean for numeric columns\n",
    "#     df_mean = df.groupby('FileName', as_index=False).mean()\n",
    "\n",
    "#     # Clip values to the range [1, 7]\n",
    "#     for column in df_mean.columns:\n",
    "#         if df_mean[column].dtype in ['float64', 'int64']:\n",
    "#             df_mean[column] = df_mean[column].clip(lower=1, upper=7)\n",
    "\n",
    "#     return df_mean\n",
    "\n",
    "# # Step 2: Process multiple CSVs and merge them\n",
    "# def merge_csvs(file_paths, output_path):\n",
    "#     processed_dfs = []\n",
    "\n",
    "#     # Process each file\n",
    "#     for file_path in file_paths:\n",
    "#         processed_dfs.append(process_csv(file_path))\n",
    "\n",
    "#     # Merge all processed DataFrames on 'Filename'\n",
    "#     merged_df = processed_dfs[0]\n",
    "#     for df in processed_dfs[1:]:\n",
    "#         merged_df = pd.merge(merged_df, df, on='FileName', how='inner')\n",
    "\n",
    "#     # Save the merged DataFrame to a new CSV\n",
    "#     merged_df.to_csv(output_path, index=False)\n",
    "#     return merged_df\n",
    "\n",
    "# # Step 3: Specify the input file paths and output file path\n",
    "# file_paths = [\n",
    "#     r\"D:\\Downloads\\MelRegression\\MelRegression\\EmoAct\\20250122_1\\test_predictions.csv\",\n",
    "#     r\"D:\\Downloads\\MelRegression\\MelRegression\\EmoVal\\20250122_2\\test_predictions.csv\",\n",
    "#     r\"D:\\Downloads\\MelRegression\\MelRegression\\EmoDom\\20250123_1\\test_predictions.csv\",\n",
    "# ]\n",
    "# output_path = r\"D:\\Downloads\\MelRegression\\output.csv\"\n",
    "\n",
    "# # Merge the CSVs\n",
    "# df = merge_csvs(file_paths, output_path)\n",
    "\n",
    "# print(f\"Merged CSV saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # # Read the CSV file\n",
    "# # df = pd.read_csv(\"your_file.csv\")\n",
    "\n",
    "# # Change column names\n",
    "# # Option 1: Rename specific columns\n",
    "# df.rename(columns={\"Filename\": \"FileName\",\n",
    "#                    \"Activation\": \"EmoAct\", \n",
    "#                    \"Valence\": \"EmoVal\",\n",
    "#                    \"Domination\": \"EmoDom\",\n",
    "#                   }, inplace=True)\n",
    "\n",
    "# # Save the updated DataFrame back to CSV\n",
    "# df.to_csv(\"./updated_file.csv\", index=False)\n",
    "\n",
    "# print(\"Column names updated successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
