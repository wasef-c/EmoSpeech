{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Paolo\\Documents\\carol_emo_rec\\MLLM\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [02:22<00:00, 28.56s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2AudioForConditionalGeneration, AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\")\n",
    "model = Qwen2AudioForConditionalGeneration.from_pretrained(\"Qwen/Qwen2-Audio-7B-Instruct\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import Qwen2AudioForConditionalGeneration, AutoProcessor\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# Replace 'your_dataset_name' with the name of your Hugging Face dataset\n",
    "dataset = load_dataset(\"cairocode/IEMO_WAV_002\")\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoProcessor, Qwen2AudioForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from io import BytesIO\n",
    "\n",
    "# Define the emotion mapping\n",
    "emotion_mapping = {\n",
    "    \"Neutral\": 0,\n",
    "    \"Happy\": 1,\n",
    "    \"Sad\": 2,\n",
    "    \"Angry\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "# Define the filter function with an argument\n",
    "def create_filter_function(spk_id):\n",
    "    def filter_m_examples(example):\n",
    "        return example[\"label\"] != 4 and example[\"label\"] != 5 and example[\"speakerID\"] == spk_id\n",
    "    return filter_m_examples\n",
    "\n",
    "# Use the filter function with the specific speaker ID\n",
    "spk_id = 2\n",
    "filter_function = create_filter_function(spk_id)\n",
    "ds_002 = dataset['train'].filter(filter_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audio', 'label', 'valence', 'arousal', 'domination', 'arousal_norm', 'valence_norm', 'speakerID', 'utterance_id', 'transcript', 'speaker_id'],\n",
      "    num_rows: 1340\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "def group_by_label(dataset, label_key):\n",
    "    \"\"\"Group dataset samples by label.\"\"\"\n",
    "    label_groups = defaultdict(list)\n",
    "    for sample in dataset:\n",
    "        label = sample[label_key]\n",
    "        label_groups[label].append(sample)\n",
    "    return label_groups\n",
    "\n",
    "def create_balanced_batches(dataset, label_key, batch_size):\n",
    "    \"\"\"Create balanced batches ensuring at least one sample per label.\"\"\"\n",
    "    label_groups = group_by_label(dataset, label_key)\n",
    "    batches = []\n",
    "    labels = list(label_groups.keys())\n",
    "    \n",
    "    while any(len(label_groups[label]) > 0 for label in labels):\n",
    "        batch = []\n",
    "        random.shuffle(labels)  # Shuffle labels for randomness\n",
    "        for label in labels:\n",
    "            if len(batch) < batch_size and len(label_groups[label]) > 0:\n",
    "                batch.append(label_groups[label].pop(0))  # Take one sample\n",
    "        \n",
    "        # Fill the remaining spots in the batch\n",
    "        remaining_samples = [\n",
    "            sample for label in labels\n",
    "            for sample in label_groups[label][:max(0, batch_size - len(batch))]\n",
    "        ]\n",
    "        random.shuffle(remaining_samples)  # Add randomness to the selection\n",
    "        batch.extend(remaining_samples[:batch_size - len(batch)])\n",
    "        \n",
    "        batches.append(batch)\n",
    "    \n",
    "    return batches\n",
    "\n",
    "def balanced_batches_as_datasets(dataset, label_key, batch_size):\n",
    "    \"\"\"Create balanced batches and return them as a list of Dataset objects.\"\"\"\n",
    "    batches = create_balanced_batches(dataset, label_key, batch_size)\n",
    "    dataset_batches = [\n",
    "        Dataset.from_dict({key: [sample[key] for sample in batch] for key in dataset.column_names})\n",
    "        for batch in batches\n",
    "    ]\n",
    "    return dataset_batches\n",
    "\n",
    "# Example usage\n",
    "# Assuming `train_dataset` is a Hugging Face Dataset and labels are in the 'label' column\n",
    "batch_size = 8\n",
    "balanced_dataset_batches = balanced_batches_as_datasets(ds, 'label', batch_size)\n",
    "\n",
    "# Combine batches back into a single Dataset if needed\n",
    "final_dataset = Dataset.from_dict({\n",
    "    key: [sample for batch in balanced_dataset_batches for sample in batch[key]]\n",
    "    for key in ds.column_names\n",
    "})\n",
    "\n",
    "print(final_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8 range(0, 8)\n",
      " | Actual Label: 3 | Response: Understood, I will use the provided information to better understand the emotions expressed by the person. | Transcript: That's out of control.\n",
      " | Actual Label: 1 | Response: Happy | Transcript: Well Vegas was awesome.\n",
      " | Actual Label: 2 | Response: Based on the tone and context provided, it's likely that the speaker is feeling sad. This can be inferred from the fact that they mentioned getting the mail and asking if she saw their letter, which suggests a sense of longing or disappointment. Additionally, the use of a sigh at the end of the sentence further emphasizes a feeling of sadness. | Transcript: Did you get the mail? So you saw my letter?\n",
      " | Actual Label: 0 | Response: Understood, I will use the provided information to better understand the person's emotions in future interactions. | Transcript: Excuse me.\n",
      " | Actual Label: 0 | Response: Neutral | Transcript: Clearly.  You know, do you have like a supervisor or something?\n",
      " | Actual Label: 1 | Response: Happy | Transcript: Um- Yes.  It was very romantic.\n",
      " | Actual Label: 2 | Response: I'm sorry, but I need more information about the person and the situation to provide a accurate understanding of their emotions. Can you please provide more context or details? | Transcript: Just, you know, kicking myself.\n",
      " | Actual Label: 2 | Response: Understood. Based on the provided information, I can infer that the person is feeling sad. | Transcript: There's people that have given more though, you know?\n",
      "8 16 range(8, 16)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 64\u001b[0m\n\u001b[0;32m     42\u001b[0m speaker_ids \u001b[38;5;241m=\u001b[39m [ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeakerID\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m batch_indices]\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#     # Process conversations\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# conversations = [\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#     [\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#     for i in batch_indices\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m conversations \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     65\u001b[0m     [\n\u001b[0;32m     66\u001b[0m         {\n\u001b[0;32m     67\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     69\u001b[0m                 \u001b[38;5;66;03m# Only add \"The correct answer was ...\" if it's not the first in the batch\u001b[39;00m\n\u001b[0;32m     70\u001b[0m                 \u001b[38;5;241m*\u001b[39m(\n\u001b[0;32m     71\u001b[0m                     [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following is an example of this person expressing this emotion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreverse_emotion_mapping[actual_labels[i]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, use this to understand this person more.\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[0;32m     72\u001b[0m                     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m batch_end\n\u001b[0;32m     73\u001b[0m                     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m     74\u001b[0m                 ),\n\u001b[0;32m     75\u001b[0m                 {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m: ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m]},\n\u001b[0;32m     76\u001b[0m \n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m                 \u001b[38;5;241m*\u001b[39m(\n\u001b[0;32m     79\u001b[0m                     [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANSWER IN ONE WORD ONLY: Is she happy, sad, angry or neutral in this audio clip? Answer in one word. Use what you learned from previous messages\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[0;32m     80\u001b[0m                     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m batch_end \u001b[38;5;129;01mand\u001b[39;00m i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     81\u001b[0m                     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m     82\u001b[0m                 ),\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m                 \u001b[38;5;66;03m# {\"type\": \"text\", \"text\": \"Is she happy, sad, angry or neutral? Answer in one word\"}\u001b[39;00m\n\u001b[0;32m     85\u001b[0m             ]\n\u001b[0;32m     86\u001b[0m         }\n\u001b[0;32m     87\u001b[0m     ]\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m batch_indices\n\u001b[0;32m     89\u001b[0m ]\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# print(i)\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \n\u001b[0;32m     92\u001b[0m \n\u001b[0;32m     93\u001b[0m \n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Prepare text inputs\u001b[39;00m\n\u001b[0;32m     95\u001b[0m text \u001b[38;5;241m=\u001b[39m [processor\u001b[38;5;241m.\u001b[39mapply_chat_template(conversation, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m conversation \u001b[38;5;129;01min\u001b[39;00m conversations]\n",
      "Cell \u001b[1;32mIn[11], line 71\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m speaker_ids \u001b[38;5;241m=\u001b[39m [ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspeakerID\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m batch_indices]\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m#     # Process conversations\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# conversations = [\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#     [\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#     for i in batch_indices\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# ]\u001b[39;00m\n\u001b[0;32m     64\u001b[0m conversations \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     65\u001b[0m     [\n\u001b[0;32m     66\u001b[0m         {\n\u001b[0;32m     67\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[0;32m     69\u001b[0m                 \u001b[38;5;66;03m# Only add \"The correct answer was ...\" if it's not the first in the batch\u001b[39;00m\n\u001b[0;32m     70\u001b[0m                 \u001b[38;5;241m*\u001b[39m(\n\u001b[1;32m---> 71\u001b[0m                     [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following is an example of this person expressing this emotion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreverse_emotion_mapping[actual_labels[i]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, use this to understand this person more.\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[0;32m     72\u001b[0m                     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m batch_end\n\u001b[0;32m     73\u001b[0m                     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m     74\u001b[0m                 ),\n\u001b[0;32m     75\u001b[0m                 {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m: ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m'\u001b[39m][i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m'\u001b[39m]},\n\u001b[0;32m     76\u001b[0m \n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m                 \u001b[38;5;241m*\u001b[39m(\n\u001b[0;32m     79\u001b[0m                     [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANSWER IN ONE WORD ONLY: Is she happy, sad, angry or neutral in this audio clip? Answer in one word. Use what you learned from previous messages\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[0;32m     80\u001b[0m                     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m batch_end \u001b[38;5;129;01mand\u001b[39;00m i\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     81\u001b[0m                     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m     82\u001b[0m                 ),\n\u001b[0;32m     83\u001b[0m \n\u001b[0;32m     84\u001b[0m                 \u001b[38;5;66;03m# {\"type\": \"text\", \"text\": \"Is she happy, sad, angry or neutral? Answer in one word\"}\u001b[39;00m\n\u001b[0;32m     85\u001b[0m             ]\n\u001b[0;32m     86\u001b[0m         }\n\u001b[0;32m     87\u001b[0m     ]\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m batch_indices\n\u001b[0;32m     89\u001b[0m ]\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# print(i)\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \n\u001b[0;32m     92\u001b[0m \n\u001b[0;32m     93\u001b[0m \n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Prepare text inputs\u001b[39;00m\n\u001b[0;32m     95\u001b[0m text \u001b[38;5;241m=\u001b[39m [processor\u001b[38;5;241m.\u001b[39mapply_chat_template(conversation, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m conversation \u001b[38;5;129;01min\u001b[39;00m conversations]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
